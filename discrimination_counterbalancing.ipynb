{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Discrimination Experiment Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import random \n",
    "import copy \n",
    "import sqlite3\n",
    "import sys\n",
    "import numpy as np \n",
    "from itertools import permutations  \n",
    "import itertools\n",
    "from itertools import combinations\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubdirTargetInfo(directory):\n",
    "    \"\"\"\n",
    "    Indexes into the json file of each image and recursively extracts image characteristics\n",
    "    All object (target image) instances are added to obs_bins (main list of all images)\n",
    "    Args: \n",
    "        directory = path to cleaned stimuli folder\n",
    "    Returns:\n",
    "        obs_bins = instance of Observation_bins class that has depth_ob (instance) for every target image\n",
    "    \"\"\"\n",
    "    obs = {}\n",
    "    for folder in os.listdir(directory): #recursively goes through all the folders\n",
    "        if folder != '.DS_Store':\n",
    "            for file in os.listdir(directory + '/' + folder):\n",
    "                filepath = directory + '/' + folder + '/' + file\n",
    "                if \".ipynb_checkpoints\" not in str(filepath):\n",
    "                    if filepath.endswith(\".json\"):\n",
    "                        output_json = json.load(open(filepath)) #loads each data.json file\n",
    "                        objects = output_json['objects'] \n",
    "                        for obj in objects:\n",
    "                            cp = obj[\"crossing_point\"]\n",
    "                            cp = cp[0] #indexes to the dict\n",
    "                            depth = cp['depth']\n",
    "                            obs[folder] = depth\n",
    "\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/prachi/Documents/depth_duration/mar3_depthDuration_stimuli/final_stimuli'\n",
    "\n",
    "# path = '/Users/prachimahableshwarkar/Documents/GW/Depth_MTurk/depth_duration_MTurk/depth_duration_stimuli'\n",
    "observations = getSubdirTargetInfo(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort observations by increasing depth (dict value)\n",
    "sorted_tuples = sorted(observations.items(), key=operator.itemgetter(1))\n",
    "sorted_dict = {k: v for k, v in sorted_tuples}\n",
    "\n",
    "# create groups of 4 from low to high depth --> 48 groups total \n",
    "grouped_observations = [sorted_tuples[i*4:(i*4)+4] for i in range(48)]\n",
    "len(grouped_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "3 (48,)\n"
     ]
    }
   ],
   "source": [
    "# tuples represent the indeces of images within the 4 image group \n",
    "# each sublist has 2 combinations with no image repetition \n",
    "combs = [[(0,1),(2,3)], [(0,2), (1,3)], [(0,3), (1,2)]]\n",
    "bins_combinations = [copy.deepcopy(combs),copy.deepcopy(combs),copy.deepcopy(combs),\n",
    "                     copy.deepcopy(combs),copy.deepcopy(combs),copy.deepcopy(combs),\n",
    "                     copy.deepcopy(combs),copy.deepcopy(combs),copy.deepcopy(combs),\n",
    "                     copy.deepcopy(combs),copy.deepcopy(combs),copy.deepcopy(combs),\n",
    "                     copy.deepcopy(combs),copy.deepcopy(combs),copy.deepcopy(combs),\n",
    "                     copy.deepcopy(combs),copy.deepcopy(combs),copy.deepcopy(combs),\n",
    "                     copy.deepcopy(combs),copy.deepcopy(combs),copy.deepcopy(combs),\n",
    "                     copy.deepcopy(combs),copy.deepcopy(combs),copy.deepcopy(combs),\n",
    "                     copy.deepcopy(combs),copy.deepcopy(combs),copy.deepcopy(combs),\n",
    "                     copy.deepcopy(combs),copy.deepcopy(combs),copy.deepcopy(combs),\n",
    "                     copy.deepcopy(combs),copy.deepcopy(combs),copy.deepcopy(combs),\n",
    "                     copy.deepcopy(combs),copy.deepcopy(combs),copy.deepcopy(combs),\n",
    "                     copy.deepcopy(combs),copy.deepcopy(combs),copy.deepcopy(combs),\n",
    "                     copy.deepcopy(combs),copy.deepcopy(combs),copy.deepcopy(combs),\n",
    "                     copy.deepcopy(combs),copy.deepcopy(combs),copy.deepcopy(combs),\n",
    "                     copy.deepcopy(combs),copy.deepcopy(combs),copy.deepcopy(combs)]\n",
    "print(len(bins_combinations))\n",
    "\n",
    "sequences = np.array([[None]*48]*3, dtype=object)\n",
    "print(len(sequences), sequences[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in range(3): # 3 sequences total to completely cover the set of comparisons \n",
    "    for i in range(len(bins_combinations)): # 48 bins\n",
    "        # randomly select a list of combos \n",
    "        # the random pick is a list of two sets of image combos within that bin \n",
    "        random_picks = random.choice(bins_combinations[i])\n",
    "        random_idx = bins_combinations[i].index(random_picks)\n",
    "\n",
    "        # remove the selected image index combo \n",
    "        del bins_combinations[i][random_idx]\n",
    "\n",
    "        # add selected combo to sequence[seq]\n",
    "        sequences[seq][i]= random_picks\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48,)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 3), (1, 2)]"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Images based on Sequence\n",
    "\n",
    "#### Create image order rotation sequence too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = '/Users/prachi/Documents/depth_duration/depth_discrimination/discrimination_sequences'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_dictionaries = []\n",
    "rotated_sequence_dictionaries = [] # order of images is flipped\n",
    "seq_names = ['c0', 'c1', 'c2']\n",
    "durations = [250, 1000, 250, 1000, 250, 1000, 250, 1000, 250, 1000,\n",
    "             250, 1000, 250, 1000, 250, 1000, 250, 1000, 250, 1000,\n",
    "             250, 1000, 250, 1000, 250, 1000, 250, 1000, 250, 1000,\n",
    "             250, 1000, 250, 1000, 250, 1000, 250, 1000, 250, 1000,\n",
    "             250, 1000, 250, 1000, 250, 1000, 250, 1000, 250, 1000,\n",
    "             250, 1000, 250, 1000, 250, 1000, 250, 1000,\n",
    "             250, 1000, 250, 1000, 250, 1000, 250, 1000, 250, 1000,\n",
    "             250, 1000, 250, 1000, 250, 1000, 250, 1000, 250, 1000,\n",
    "             250, 1000, 250, 1000, 250, 1000, 250, 1000, 250, 1000,\n",
    "             250, 1000, 250, 1000, 250, 1000, 250, 1000]\n",
    "# shuffle durations \n",
    "random.shuffle(durations)\n",
    "\n",
    "for i in range(len(sequences)):\n",
    "    seq = [] \n",
    "    rotated_seq = []\n",
    "    sequence_name = seq_names[i]\n",
    "    rotated_seq_name = seq_names[i] + '_rotated' # order rotated\n",
    "    num = 0 # iterator for bins (48 total)\n",
    "    dur_num = 0 # iterator that ensures each mask is unique and is the index for durations (list)\n",
    "    for bin_trials in sequences[i]: # loop through the 48 bins\n",
    "        for trial in bin_trials: # loop through the 2 sets of image combos ex. [(0,1), (2, 3)]\n",
    "            img0_index = trial[0]\n",
    "            img1_index = trial[1]\n",
    "            dict_trial = {}\n",
    "            dict_trial[\"sequence\"] = sequence_name\n",
    "            dict_trial[\"duration\"] = durations[num]\n",
    "            dict_trial[\"depth_0\"] = grouped_observations[num][img0_index][1]\n",
    "            dict_trial[\"depth_1\"] = grouped_observations[num][img1_index][1]\n",
    "\n",
    "            targetimg_0 = grouped_observations[num][img0_index][0]\n",
    "            targetimg_1 = grouped_observations[num][img1_index][0]\n",
    "            # this has to be the path on the server\n",
    "            targetimg_0_path = \"depth_discrimination_stimuli/\" + targetimg_0 + '/' + targetimg_0 + '-target.png'\n",
    "            targetimg_1_path = \"depth_discrimination_stimuli/\" + targetimg_1 + '/' + targetimg_1 + '-target.png'\n",
    "\n",
    "            dict_trial[\"image_path_target_0\"] = targetimg_0_path\n",
    "            dict_trial[\"image_path_target_1\"] = targetimg_1_path\n",
    "\n",
    "            dict_trial[\"mask_path\"] = \"masks/mask_\" + str(num) + \".jpg\"\n",
    "            dict_trial[\"fixation_path\"] = \"fixation.jpg\"\n",
    "\n",
    "            seq.append(dict_trial)\n",
    "            ###################### Rotated sequence ######################\n",
    "            rotated_dict_trial = {}\n",
    "            rotated_dict_trial[\"sequence\"] = rotated_seq_name\n",
    "            rotated_dict_trial[\"duration\"] = durations[dur_num]\n",
    "            dur_num += 1\n",
    "            rotated_dict_trial[\"depth_0\"] = grouped_observations[num][img1_index][1]\n",
    "            rotated_dict_trial[\"depth_1\"] = grouped_observations[num][img0_index][1]\n",
    "\n",
    "            r_targetimg_0 = grouped_observations[num][img1_index][0]\n",
    "            r_targetimg_1 = grouped_observations[num][img0_index][0]\n",
    "            # this has to be the path on the server\n",
    "            r_targetimg_0_path = \"depth_discrimination_stimuli/\" + r_targetimg_1 + '/' + r_targetimg_1 + '-target.png'\n",
    "            r_targetimg_1_path = \"depth_discrimination_stimuli/\" + r_targetimg_0 + '/' + r_targetimg_0 + '-target.png'\n",
    "\n",
    "            rotated_dict_trial[\"image_path_target_0\"] = r_targetimg_1_path\n",
    "            rotated_dict_trial[\"image_path_target_1\"] = r_targetimg_0_path\n",
    "\n",
    "            rotated_dict_trial[\"mask_path\"] = \"masks/mask_\" + str(dur_num) + \".jpg\"\n",
    "            rotated_dict_trial[\"fixation_path\"] = \"fixation.jpg\"\n",
    "\n",
    "            rotated_seq.append(rotated_dict_trial)\n",
    "\n",
    "        num += 1\n",
    "\n",
    "    # shuffle the order of trials so that trials are not in order of increasing depth \n",
    "    # use the same random seed for sequence & it's rotation so trials match in images \n",
    "    random.Random(i).shuffle(seq)\n",
    "    random.Random(i).shuffle(rotated_seq)\n",
    "    random.Random(i).shuffle(seq)\n",
    "    random.Random(i).shuffle(rotated_seq)\n",
    "\n",
    "    # reshuffle durations so that each sequence has a different duration order \n",
    "    random.shuffle(durations)\n",
    "    \n",
    "    sequence_dictionaries.append(seq)\n",
    "    rotated_sequence_dictionaries.append(rotated_seq)\n",
    "\n",
    "    \n",
    "for sequence in sequence_dictionaries:\n",
    "    name = sequence[0][\"sequence\"]\n",
    "    path = destination + '/' + name + '.json'\n",
    "    # creates json file for the sequence \n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(sequence , f)  \n",
    "        \n",
    "for rotated_sequence in rotated_sequence_dictionaries:\n",
    "    rotated_name = rotated_sequence[0][\"sequence\"]\n",
    "    rotated_path = destination + '/' + rotated_name + '.json'\n",
    "    # creates json file for the sequence \n",
    "    with open(rotated_path, 'w') as f:\n",
    "        json.dump(rotated_sequence , f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate Sequence by Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_master_sequence(jsonpath):\n",
    "    return json.load(open(jsonpath))\n",
    "\n",
    "def rotate_sequence(previous_seq):\n",
    "    \"\"\"\n",
    "    Rotates each trial's duration assignment based on previous sequence \n",
    "    250 --> 1000\n",
    "    1000 --> 250\n",
    "    \"\"\"\n",
    "    rotated = previous_seq\n",
    "    for i in range(len(previous_seq)):\n",
    "        duration = previous_seq[i]['duration']\n",
    "        if duration == 1000:\n",
    "            new_duration = 250\n",
    "        else:\n",
    "            new_duration = 1000\n",
    "        rotated[i]['duration'] = new_duration\n",
    "        \n",
    "    return rotated\n",
    "\n",
    "def create_duration_rotations(jsonpath, exit, name):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        jsonpath = path to master json created through sequence pipeline\n",
    "        exit = destination path for new jsons \n",
    "        name = i.e. V1 \n",
    "    \n",
    "    Creates sequences rotated by duration so that all images in the master sequence are seen at each duration\n",
    "    (across participants)\n",
    "        \n",
    "    \"\"\"\n",
    "    master = load_master_sequence(jsonpath)\n",
    "    \n",
    "    r = rotate_sequence(master)\n",
    "    r_path = exit + '/' + name + '_dr.json' # duration rotated sequence\n",
    "    #creates json file for the sequence \n",
    "    with open(r_path, 'w') as f:\n",
    "        json.dump(r , f)\n",
    "\n",
    "        \n",
    "def main_seq_rotations(json_folderpath, exit):\n",
    "    \"\"\"\n",
    "    Create rotated sequence for each sequence in the folder\n",
    "    \"\"\"\n",
    "    for file in os.listdir(json_folderpath):\n",
    "        name = file.split(\".\")[0]\n",
    "        jsonpath = json_folderpath + \"/\" + file\n",
    "        try:\n",
    "            create_duration_rotations(jsonpath, exit, name)\n",
    "        except:\n",
    "            print(\"Failed to create json rotations for: \", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to create json rotations for:  .DS_Store\n",
      "Failed to create json rotations for:  .ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "main_seq_rotations(destination,destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequences:\n",
    "Original Sequence: c0 \n",
    "- c0_dr: duration assigned is rotated\n",
    "- c0_rotated: order of images if flipped\n",
    "- c0_rotated_dr: duration assigned is rotated\n",
    "\n",
    "3 original sequences \n",
    "- covers the whole space of 2 trial combinations within the 48 bins \n",
    "- 96 trials total, with 2 trials from each bin \n",
    "\n",
    "\n",
    "12 Total sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for js in os.listdir('/Users/prachi/Documents/depth_duration/depth_discrimination/discrimination_sequences'):\n",
    "    if '.json' in js:\n",
    "        count += 1\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 min, 1 dollar\n",
    "- test time it takes to complete experiment\n",
    "\n",
    "Consider running experiment bundles\n",
    "- prefer orthogonal tasks\n",
    "- counterbalance the order of the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
