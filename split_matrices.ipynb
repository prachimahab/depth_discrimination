{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8x8 Matrix: Accuracy, RT, Task, Duration \n",
    "\n",
    "Input data is split randomly in half ~10,000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy \n",
    "import scipy.stats as stats\n",
    "from scipy.stats import sem \n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_discrim_path = '/Users/prachimahableshwarkar/Documents/GW/Depth_MTurk/depth_discrimination/TAC_discrim_datafiles/matched_discrim_data/final_discrim.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_discrim = pd.read_csv(final_discrim_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_VE_data_250_path = '/Users/prachimahableshwarkar/Documents/GW/Depth_MTurk/verbal_judgement_analysis/TAC_data/matched_VE_data/normalized_250_data.csv'\n",
    "\n",
    "n_VE_data_1000_path = '/Users/prachimahableshwarkar/Documents/GW/Depth_MTurk/verbal_judgement_analysis/TAC_data/matched_VE_data/normalized_1000_data.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_VE_data_250 = pd.read_csv(n_VE_data_250_path)\n",
    "n_VE_data_1000 = pd.read_csv(n_VE_data_1000_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stimuli(duration_df):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        duration df \n",
    "    Returns:\n",
    "        all_stimuli\n",
    "    \"\"\"\n",
    "    \n",
    "    stimuli = set()\n",
    "    for idx, row in duration_df.iterrows():\n",
    "        stimulus = row[\"stimulus\"]\n",
    "        stimuli.add(stimulus)\n",
    "        \n",
    "    return list(stimuli)\n",
    "\n",
    "def rand_data(duration_df, proportion):\n",
    "    \"\"\"\n",
    "    Args\n",
    "        Data post outlier removal: i.e. cleaned_data \n",
    "        proportion - amount of data in each split (0.5 for 50/50 split)\n",
    "    \"\"\"\n",
    "    \n",
    "    stimuli = get_stimuli(duration_df)\n",
    "    \n",
    "    rand_y = []\n",
    "    rand_std = []\n",
    "    rand_ste = []\n",
    "    rand_stim = []\n",
    "    \n",
    "    rand_all_ys = []\n",
    "    \n",
    "    rand_subjIDs = []\n",
    "\n",
    "    grouped = duration_df.groupby(duration_df.stimulus) \n",
    "    for stim in stimuli:   \n",
    "        stim_df = grouped.get_group(stim)\n",
    "        stim_df_estimates = stim_df['depth_estimate'].tolist()\n",
    "        stim_df_subjIDs = stim_df['subjID'].tolist()\n",
    "        \n",
    "        # Shuffle two lists with same order\n",
    "        # Using zip() + * operator + shuffle()\n",
    "        temp = list(zip(stim_df_subjIDs, stim_df_estimates))\n",
    "        random.shuffle(temp)\n",
    "        shuffled_subjIDs, shuffled_estimates = zip(*temp)\n",
    "        # res1 and res2 come out as tuples, and so must be converted to lists.\n",
    "        shuffled_subjIDs, shuffled_estimates = list(shuffled_subjIDs), list(shuffled_estimates)\n",
    "        \n",
    "        rand_all_ys.append(np.array(shuffled_estimates[0:int(len(shuffled_estimates)*proportion)]))\n",
    "        rand_subjIDs.append(np.array(shuffled_subjIDs[0:int(len(shuffled_subjIDs)*proportion)]))\n",
    "        \n",
    "        estim_avg_df0 = np.mean(np.array(shuffled_estimates[0:int(len(shuffled_estimates)*proportion)]))\n",
    "        estim_std = np.std(np.array(shuffled_estimates[0:int(len(shuffled_estimates)*proportion)]))\n",
    "        estim_ste = stats.sem(np.array(shuffled_estimates[0:int(len(shuffled_estimates)*proportion)]))\n",
    "        \n",
    "        rand_y.append(estim_avg_df0) \n",
    "        rand_std.append(estim_std)\n",
    "        rand_ste.append(estim_ste)\n",
    "        rand_stim.append(stim)\n",
    "    \n",
    "    rand_y = np.array(rand_y).reshape(1,-1)[0]\n",
    "    rand_std = np.array(rand_std).reshape(1,-1)[0]\n",
    "    rand_ste = np.array(rand_ste).reshape(1,-1)[0]\n",
    "    rand_stim = np.array(rand_stim).reshape(1,-1)[0]\n",
    "    \n",
    "    rand_df = pd.DataFrame(columns=('subjID', 'stimulus', 'depth_estimate'))\n",
    "    \n",
    "    c = 0\n",
    "    # loop through all stimuli\n",
    "    for i, stim in enumerate(rand_stim):\n",
    "        # loop through all the subjects that have data for that stimulus\n",
    "        for j in range(len(rand_subjIDs[i])):\n",
    "            # add to the df the subject id, the subjects estimate, and the stimulus name\n",
    "            # df has a seperate row for each subjects response \n",
    "            rand_df.loc[c] = [rand_subjIDs[i][j], stim, rand_all_ys[i][j]]\n",
    "            c += 1\n",
    "            \n",
    "    return [rand_y, rand_std, rand_ste, rand_stim], rand_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "r0_250, r0_250_df = rand_data(n_VE_data_250, 0.5)\n",
    "r0_1000, r0_1000_df = rand_data(n_VE_data_1000, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subjID</th>\n",
       "      <th>experimentName</th>\n",
       "      <th>versionName</th>\n",
       "      <th>sequenceName</th>\n",
       "      <th>url</th>\n",
       "      <th>selected_row</th>\n",
       "      <th>windowWidth</th>\n",
       "      <th>windowHeight</th>\n",
       "      <th>screenWidth</th>\n",
       "      <th>...</th>\n",
       "      <th>duration</th>\n",
       "      <th>actual_depth</th>\n",
       "      <th>depth_estimate</th>\n",
       "      <th>trial_RT</th>\n",
       "      <th>log_sceneDuration</th>\n",
       "      <th>unitSelection</th>\n",
       "      <th>experimentTime</th>\n",
       "      <th>totalTime</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>810087</td>\n",
       "      <td>DepthScenes</td>\n",
       "      <td>duration_manipulation_targetAtFixation</td>\n",
       "      <td>jsons/VE250_randls_6.json</td>\n",
       "      <td>http://54.173.230.142/FacialAge/BNav_EC2/Depth...</td>\n",
       "      <td>111</td>\n",
       "      <td>1440</td>\n",
       "      <td>757</td>\n",
       "      <td>1440</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>3.9835</td>\n",
       "      <td>1.431018</td>\n",
       "      <td>4443</td>\n",
       "      <td>250</td>\n",
       "      <td>feet</td>\n",
       "      <td>1682664</td>\n",
       "      <td>1792976</td>\n",
       "      <td>40</td>\n",
       "      <td>Woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>810087</td>\n",
       "      <td>DepthScenes</td>\n",
       "      <td>duration_manipulation_targetAtFixation</td>\n",
       "      <td>jsons/VE250_randls_6.json</td>\n",
       "      <td>http://54.173.230.142/FacialAge/BNav_EC2/Depth...</td>\n",
       "      <td>111</td>\n",
       "      <td>1440</td>\n",
       "      <td>757</td>\n",
       "      <td>1440</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>1.5580</td>\n",
       "      <td>1.788773</td>\n",
       "      <td>5052</td>\n",
       "      <td>250</td>\n",
       "      <td>feet</td>\n",
       "      <td>1682664</td>\n",
       "      <td>1792976</td>\n",
       "      <td>40</td>\n",
       "      <td>Woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>810087</td>\n",
       "      <td>DepthScenes</td>\n",
       "      <td>duration_manipulation_targetAtFixation</td>\n",
       "      <td>jsons/VE250_randls_6.json</td>\n",
       "      <td>http://54.173.230.142/FacialAge/BNav_EC2/Depth...</td>\n",
       "      <td>111</td>\n",
       "      <td>1440</td>\n",
       "      <td>757</td>\n",
       "      <td>1440</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>3.5340</td>\n",
       "      <td>1.073264</td>\n",
       "      <td>4196</td>\n",
       "      <td>249</td>\n",
       "      <td>feet</td>\n",
       "      <td>1682664</td>\n",
       "      <td>1792976</td>\n",
       "      <td>40</td>\n",
       "      <td>Woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>810087</td>\n",
       "      <td>DepthScenes</td>\n",
       "      <td>duration_manipulation_targetAtFixation</td>\n",
       "      <td>jsons/VE250_randls_6.json</td>\n",
       "      <td>http://54.173.230.142/FacialAge/BNav_EC2/Depth...</td>\n",
       "      <td>111</td>\n",
       "      <td>1440</td>\n",
       "      <td>757</td>\n",
       "      <td>1440</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>1.6565</td>\n",
       "      <td>1.252141</td>\n",
       "      <td>3365</td>\n",
       "      <td>256</td>\n",
       "      <td>feet</td>\n",
       "      <td>1682664</td>\n",
       "      <td>1792976</td>\n",
       "      <td>40</td>\n",
       "      <td>Woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>810087</td>\n",
       "      <td>DepthScenes</td>\n",
       "      <td>duration_manipulation_targetAtFixation</td>\n",
       "      <td>jsons/VE250_randls_6.json</td>\n",
       "      <td>http://54.173.230.142/FacialAge/BNav_EC2/Depth...</td>\n",
       "      <td>111</td>\n",
       "      <td>1440</td>\n",
       "      <td>757</td>\n",
       "      <td>1440</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>4.0370</td>\n",
       "      <td>0.894386</td>\n",
       "      <td>3746</td>\n",
       "      <td>248</td>\n",
       "      <td>feet</td>\n",
       "      <td>1682664</td>\n",
       "      <td>1792976</td>\n",
       "      <td>40</td>\n",
       "      <td>Woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9648</th>\n",
       "      <td>23994</td>\n",
       "      <td>754962</td>\n",
       "      <td>DepthScenes</td>\n",
       "      <td>duration_manipulation_targetAtFixation</td>\n",
       "      <td>jsons/VE250_randls_8.json</td>\n",
       "      <td>http://54.173.230.142/FacialAge/BNav_EC2/Depth...</td>\n",
       "      <td>127</td>\n",
       "      <td>1536</td>\n",
       "      <td>722</td>\n",
       "      <td>1536</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>4.0585</td>\n",
       "      <td>1.513295</td>\n",
       "      <td>6098</td>\n",
       "      <td>250</td>\n",
       "      <td>feet</td>\n",
       "      <td>1177038</td>\n",
       "      <td>1334470</td>\n",
       "      <td>60</td>\n",
       "      <td>Woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9649</th>\n",
       "      <td>23995</td>\n",
       "      <td>754962</td>\n",
       "      <td>DepthScenes</td>\n",
       "      <td>duration_manipulation_targetAtFixation</td>\n",
       "      <td>jsons/VE250_randls_8.json</td>\n",
       "      <td>http://54.173.230.142/FacialAge/BNav_EC2/Depth...</td>\n",
       "      <td>127</td>\n",
       "      <td>1536</td>\n",
       "      <td>722</td>\n",
       "      <td>1536</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>2.8490</td>\n",
       "      <td>1.297110</td>\n",
       "      <td>5041</td>\n",
       "      <td>243</td>\n",
       "      <td>feet</td>\n",
       "      <td>1177038</td>\n",
       "      <td>1334470</td>\n",
       "      <td>60</td>\n",
       "      <td>Woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9650</th>\n",
       "      <td>23996</td>\n",
       "      <td>754962</td>\n",
       "      <td>DepthScenes</td>\n",
       "      <td>duration_manipulation_targetAtFixation</td>\n",
       "      <td>jsons/VE250_randls_8.json</td>\n",
       "      <td>http://54.173.230.142/FacialAge/BNav_EC2/Depth...</td>\n",
       "      <td>127</td>\n",
       "      <td>1536</td>\n",
       "      <td>722</td>\n",
       "      <td>1536</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>2.1070</td>\n",
       "      <td>0.972832</td>\n",
       "      <td>5996</td>\n",
       "      <td>250</td>\n",
       "      <td>feet</td>\n",
       "      <td>1177038</td>\n",
       "      <td>1334470</td>\n",
       "      <td>60</td>\n",
       "      <td>Woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9651</th>\n",
       "      <td>23997</td>\n",
       "      <td>754962</td>\n",
       "      <td>DepthScenes</td>\n",
       "      <td>duration_manipulation_targetAtFixation</td>\n",
       "      <td>jsons/VE250_randls_8.json</td>\n",
       "      <td>http://54.173.230.142/FacialAge/BNav_EC2/Depth...</td>\n",
       "      <td>127</td>\n",
       "      <td>1536</td>\n",
       "      <td>722</td>\n",
       "      <td>1536</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>2.3540</td>\n",
       "      <td>1.080925</td>\n",
       "      <td>5232</td>\n",
       "      <td>251</td>\n",
       "      <td>feet</td>\n",
       "      <td>1177038</td>\n",
       "      <td>1334470</td>\n",
       "      <td>60</td>\n",
       "      <td>Woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9652</th>\n",
       "      <td>23998</td>\n",
       "      <td>754962</td>\n",
       "      <td>DepthScenes</td>\n",
       "      <td>duration_manipulation_targetAtFixation</td>\n",
       "      <td>jsons/VE250_randls_8.json</td>\n",
       "      <td>http://54.173.230.142/FacialAge/BNav_EC2/Depth...</td>\n",
       "      <td>127</td>\n",
       "      <td>1536</td>\n",
       "      <td>722</td>\n",
       "      <td>1536</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>2.2660</td>\n",
       "      <td>0.864740</td>\n",
       "      <td>5006</td>\n",
       "      <td>250</td>\n",
       "      <td>feet</td>\n",
       "      <td>1177038</td>\n",
       "      <td>1334470</td>\n",
       "      <td>60</td>\n",
       "      <td>Woman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9653 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  subjID experimentName  \\\n",
       "0              0  810087    DepthScenes   \n",
       "1              1  810087    DepthScenes   \n",
       "2              2  810087    DepthScenes   \n",
       "3              3  810087    DepthScenes   \n",
       "4              4  810087    DepthScenes   \n",
       "...          ...     ...            ...   \n",
       "9648       23994  754962    DepthScenes   \n",
       "9649       23995  754962    DepthScenes   \n",
       "9650       23996  754962    DepthScenes   \n",
       "9651       23997  754962    DepthScenes   \n",
       "9652       23998  754962    DepthScenes   \n",
       "\n",
       "                                 versionName               sequenceName  \\\n",
       "0     duration_manipulation_targetAtFixation  jsons/VE250_randls_6.json   \n",
       "1     duration_manipulation_targetAtFixation  jsons/VE250_randls_6.json   \n",
       "2     duration_manipulation_targetAtFixation  jsons/VE250_randls_6.json   \n",
       "3     duration_manipulation_targetAtFixation  jsons/VE250_randls_6.json   \n",
       "4     duration_manipulation_targetAtFixation  jsons/VE250_randls_6.json   \n",
       "...                                      ...                        ...   \n",
       "9648  duration_manipulation_targetAtFixation  jsons/VE250_randls_8.json   \n",
       "9649  duration_manipulation_targetAtFixation  jsons/VE250_randls_8.json   \n",
       "9650  duration_manipulation_targetAtFixation  jsons/VE250_randls_8.json   \n",
       "9651  duration_manipulation_targetAtFixation  jsons/VE250_randls_8.json   \n",
       "9652  duration_manipulation_targetAtFixation  jsons/VE250_randls_8.json   \n",
       "\n",
       "                                                    url  selected_row  \\\n",
       "0     http://54.173.230.142/FacialAge/BNav_EC2/Depth...           111   \n",
       "1     http://54.173.230.142/FacialAge/BNav_EC2/Depth...           111   \n",
       "2     http://54.173.230.142/FacialAge/BNav_EC2/Depth...           111   \n",
       "3     http://54.173.230.142/FacialAge/BNav_EC2/Depth...           111   \n",
       "4     http://54.173.230.142/FacialAge/BNav_EC2/Depth...           111   \n",
       "...                                                 ...           ...   \n",
       "9648  http://54.173.230.142/FacialAge/BNav_EC2/Depth...           127   \n",
       "9649  http://54.173.230.142/FacialAge/BNav_EC2/Depth...           127   \n",
       "9650  http://54.173.230.142/FacialAge/BNav_EC2/Depth...           127   \n",
       "9651  http://54.173.230.142/FacialAge/BNav_EC2/Depth...           127   \n",
       "9652  http://54.173.230.142/FacialAge/BNav_EC2/Depth...           127   \n",
       "\n",
       "      windowWidth  windowHeight  screenWidth  ...  duration actual_depth  \\\n",
       "0            1440           757         1440  ...       250       3.9835   \n",
       "1            1440           757         1440  ...       250       1.5580   \n",
       "2            1440           757         1440  ...       250       3.5340   \n",
       "3            1440           757         1440  ...       250       1.6565   \n",
       "4            1440           757         1440  ...       250       4.0370   \n",
       "...           ...           ...          ...  ...       ...          ...   \n",
       "9648         1536           722         1536  ...       250       4.0585   \n",
       "9649         1536           722         1536  ...       250       2.8490   \n",
       "9650         1536           722         1536  ...       250       2.1070   \n",
       "9651         1536           722         1536  ...       250       2.3540   \n",
       "9652         1536           722         1536  ...       250       2.2660   \n",
       "\n",
       "     depth_estimate  trial_RT log_sceneDuration  unitSelection  \\\n",
       "0          1.431018      4443               250           feet   \n",
       "1          1.788773      5052               250           feet   \n",
       "2          1.073264      4196               249           feet   \n",
       "3          1.252141      3365               256           feet   \n",
       "4          0.894386      3746               248           feet   \n",
       "...             ...       ...               ...            ...   \n",
       "9648       1.513295      6098               250           feet   \n",
       "9649       1.297110      5041               243           feet   \n",
       "9650       0.972832      5996               250           feet   \n",
       "9651       1.080925      5232               251           feet   \n",
       "9652       0.864740      5006               250           feet   \n",
       "\n",
       "      experimentTime  totalTime  age  gender  \n",
       "0            1682664    1792976   40   Woman  \n",
       "1            1682664    1792976   40   Woman  \n",
       "2            1682664    1792976   40   Woman  \n",
       "3            1682664    1792976   40   Woman  \n",
       "4            1682664    1792976   40   Woman  \n",
       "...              ...        ...  ...     ...  \n",
       "9648         1177038    1334470   60   Woman  \n",
       "9649         1177038    1334470   60   Woman  \n",
       "9650         1177038    1334470   60   Woman  \n",
       "9651         1177038    1334470   60   Woman  \n",
       "9652         1177038    1334470   60   Woman  \n",
       "\n",
       "[9653 rows x 25 columns]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_VE_data_250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(df):\n",
    "    \"\"\"\n",
    "    * ACCURACY BASED ON THE KINECT\n",
    "    args:\n",
    "        df  \n",
    "    returns:\n",
    "        proportion of correct responses, count of correct responses, count of total trials  \n",
    "    \"\"\"\n",
    "    count_correct = 0\n",
    "    count_incorrect = 0\n",
    "    count_total = 0\n",
    "    count_missed = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        choice = row[\"discrim_choice\"]\n",
    "        if choice == 2.0:\n",
    "            count_missed += 1\n",
    "        else:    \n",
    "            count_total += 1\n",
    "            depth0 = row[\"actual_depth_0\"]\n",
    "            depth1 = row[\"actual_depth_1\"]\n",
    "            if depth0 < depth1:\n",
    "                correct_choice = 0\n",
    "            if depth0 > depth1:\n",
    "                correct_choice = 1\n",
    "            if depth0 == depth1:\n",
    "                # case where depths are equal \n",
    "                correct_choice = None\n",
    "            if choice == correct_choice:\n",
    "                count_correct += 1\n",
    "    \n",
    "    return count_correct/count_total, count_correct, count_total, count_missed\n",
    "\n",
    "def get_RT(df):\n",
    "    \"\"\"\n",
    "    Converts raw RT --> ln(RT)\n",
    "    \n",
    "    args:\n",
    "        df  \n",
    "    returns:\n",
    "        array of RTs, avg RT and std   \n",
    "    \"\"\"\n",
    "    list_RTs = []\n",
    "    for idx, row in df.iterrows():   \n",
    "        stimulus_duration = row['log_sceneDuration2']\n",
    "        RT = row[\"trial_RT\"] - stimulus_duration\n",
    "        list_RTs.append(np.log(RT))\n",
    "    \n",
    "    list_RTs = np.array(list_RTs)\n",
    "    \n",
    "    return list_RTs, np.mean(list_RTs) ,np.std(list_RTs), stats.sem(list_RTs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def individual_discrimination_stats(df):\n",
    "    '''\n",
    "    Individual discrimination performance and RT \n",
    "    '''\n",
    "    all_stim0 = df.stimulus_0.unique()\n",
    "    \n",
    "    stimuli_stats = {}\n",
    "    for stim0 in all_stim0:\n",
    "        stim0_df = df.loc[df['stimulus_0'] == stim0]\n",
    "        other_stim = stim0_df.stimulus_1.unique()[0]\n",
    "        stim1_df = df.loc[df['stimulus_1'] == stim0]\n",
    "        # df for a specific discrimination trial (collapsed on stim presentation order)\n",
    "        stim_df = pd.concat([stim0_df, stim1_df], ignore_index=True)\n",
    "        stim_250_df = stim_df[stim_df['duration'] == 250.0]\n",
    "        stim_1000_df = stim_df[stim_df['duration'] == 1000.0] \n",
    "                \n",
    "        stim_depthdiff = stim_df['depth_difference'][0]\n",
    "        \n",
    "        stim0_depth = stim_df['actual_depth_0'][0]\n",
    "        stim1_depth = stim_df['actual_depth_1'][0]\n",
    "        stim_depthbin = np.mean(np.array([stim0_depth,stim1_depth]))\n",
    "        \n",
    "        kinect_answer = stim0_df.kinect_answer.unique()[0]\n",
    "        \n",
    "        try:\n",
    "            stim_acc_250 = get_accuracy(stim_250_df)\n",
    "            stim_acc_1000 = get_accuracy(stim_1000_df)\n",
    "\n",
    "            stim_RT_250 = get_RT(stim_250_df)\n",
    "            stim_RT_1000 = get_RT(stim_1000_df)\n",
    "\n",
    "            stimuli_stats[stim0] = {'stimulus_1': other_stim,\n",
    "                                    'accuracy_250': stim_acc_250,\n",
    "                                    'accuracy_1000': stim_acc_1000,\n",
    "                                    'avg_depth': stim_depthbin,\n",
    "                                    'depthdifference': stim_depthdiff, \n",
    "                                    'RT_250': stim_RT_250,\n",
    "                                    'RT_1000': stim_RT_1000,\n",
    "                                    'kinect_answer': kinect_answer}\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return stimuli_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_discrim_performance = individual_discrimination_stats(final_discrim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_discrim_performance['depth_discrimination_stimuli/001417_2014-06-19_16-25-36_260595134347_rgbf000115-resize_5/001417_2014-06-19_16-25-36_260595134347_rgbf000115-resize_5-target.png']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_answerkey(discrim_performance, VE_data):\n",
    "    '''\n",
    "    Generates discrimination trial answer key based off of verbal judgement data\n",
    "    '''\n",
    "    answerkey = {}\n",
    "    \n",
    "    final_y = VE_data[0]\n",
    "    final_std = VE_data[1]\n",
    "    final_ste = VE_data[2]\n",
    "    final_stim = VE_data[3]\n",
    "\n",
    "    for key in discrim_performance.keys():\n",
    "        targetimg0 = key.split('/')[-1]\n",
    "        folder0 = targetimg0[:-11]\n",
    "        depth_dur_path0 = 'depth_duration_stimuli/' + folder0 + '/' + targetimg0\n",
    "        idx0 = np.where(final_stim == depth_dur_path0)[0][0]\n",
    "        avg_estim_stim0 = final_y[idx0]\n",
    "        std0 = final_std[idx0]\n",
    "        ste0 = final_ste[idx0]\n",
    "    \n",
    "        targetimg1 = discrim_performance[key]['stimulus_1'].split('/')[-1]\n",
    "        folder1 = targetimg1[:-11]\n",
    "        depth_dur_path1 = 'depth_duration_stimuli/' + folder1 + '/' + targetimg1\n",
    "        idx1= np.where(final_stim == depth_dur_path1)[0][0]\n",
    "        avg_estim_stim1 = final_y[idx1]\n",
    "        std1 = final_std[idx1]\n",
    "        ste1 = final_ste[idx1]\n",
    "    \n",
    "        kinect_answer = discrim_performance[key]['kinect_answer'].split('/')[-1]\n",
    "\n",
    "        if avg_estim_stim0 < avg_estim_stim1:\n",
    "            # Which target is CLOSER to you?\n",
    "            answer = targetimg0\n",
    "        if avg_estim_stim0 == avg_estim_stim1:\n",
    "            print(targetimg0, targetimg1)\n",
    "        if avg_estim_stim0 > avg_estim_stim1:\n",
    "            answer = targetimg1\n",
    "\n",
    "        answerkey[key] = {'stimulus_1': targetimg1,\n",
    "                                   'stimulus_0_avg_estim': avg_estim_stim0,\n",
    "                                   'stimulus_1_avg_estim': avg_estim_stim1,\n",
    "                                   'answer': answer,\n",
    "                                   'std0': std0,\n",
    "                                   'std1': std1,\n",
    "                                   'kinect_answer': kinect_answer}\n",
    "        \n",
    "    return answerkey\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak_250 = get_answerkey(all_discrim_performance, r0_250)\n",
    "ak_1000 = get_answerkey(all_discrim_performance, r0_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VE Coded Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def VE_accuracy(stim0, df, answerkey):\n",
    "    '''\n",
    "    Accuracy based on the verbal judgement data \n",
    "    '''\n",
    "    \n",
    "    \"\"\"\n",
    "    args:\n",
    "        df  \n",
    "    returns:\n",
    "        proportion of correct responses, count of correct responses, count of total trials  \n",
    "    \"\"\"\n",
    "    count_correct = 0\n",
    "    count_incorrect = 0\n",
    "    count_total = 0\n",
    "    count_missed = 0\n",
    "    \n",
    "    VE_correct_answer = answerkey[stim0]['answer']\n",
    "    kinect_correct_answer = answerkey[stim0]['kinect_answer']\n",
    "    \n",
    "    for idx, row in df.iterrows(): \n",
    "        choice = row[\"discrim_choice\"]\n",
    "        count_total += 1\n",
    "        if choice == 0.0: image_choice = row[\"stimulus_0\"]\n",
    "                \n",
    "        if choice == 1.0: image_choice = row[\"stimulus_1\"]\n",
    "                \n",
    "        if choice == 2.0: count_missed += 1\n",
    "            \n",
    "        if choice == 3.0: count_missed += 1\n",
    "        \n",
    "        try:\n",
    "            if image_choice.split('/')[-1] == VE_correct_answer: count_correct += 1\n",
    "        except: pass\n",
    "        \n",
    "#     standardError = (0.5*(1-0.5))/count_total\n",
    "    p = count_correct/count_total\n",
    "    standardError = np.sqrt((p*(1-p))/count_total)\n",
    "    \n",
    "    if VE_correct_answer == kinect_correct_answer:\n",
    "        return count_correct/count_total, count_correct, count_total, count_missed, standardError, 'pos'\n",
    "    else:\n",
    "        return count_correct/count_total, count_correct, count_total, count_missed, standardError, 'neg'\n",
    "\n",
    "    \n",
    "def main_VE_coded_discrim_accuracy(df, answerkey_250, answerkey_1000):\n",
    "    '''\n",
    "    Args:\n",
    "        df: final discrimination dataframe\n",
    "        answerkey_250 & answerkey_1000: VE coded answer key\n",
    "    '''\n",
    "    all_stim0 = df.stimulus_0.unique()\n",
    "    \n",
    "    stimuli_stats = {}\n",
    "    for stim0 in all_stim0:\n",
    "        try:\n",
    "            # dataframe for stimulus 0\n",
    "            stim0_df = df.loc[df['stimulus_0'] == stim0]\n",
    "            # name of stimulus 1\n",
    "            other_stim = stim0_df.stimulus_1.unique()[0]\n",
    "            # dataframe where stimulus 0 is presented SECOND (same trial)\n",
    "            stim1_df = df.loc[df['stimulus_1'] == stim0]\n",
    "\n",
    "            # df for a specific discrimination trial (collapsed on stim presentation order)\n",
    "            stim_df = pd.concat([stim0_df, stim1_df], ignore_index=True)\n",
    "            stim_250_df = stim_df[stim_df['duration'] == 250.0]\n",
    "            stim_1000_df = stim_df[stim_df['duration'] == 1000.0] \n",
    "\n",
    "            stim0_depth = stim_df['actual_depth_0'][0]\n",
    "            stim1_depth = stim_df['actual_depth_1'][0]\n",
    "            stim_depthbin = np.mean(np.array([stim0_depth,stim1_depth]))\n",
    "\n",
    "            stim_acc_250 = VE_accuracy(stim0, stim_250_df, answerkey_250)\n",
    "            stim_acc_1000 = VE_accuracy(stim0, stim_1000_df, answerkey_1000)\n",
    "\n",
    "            stim_RT_250 = get_RT(stim_250_df)\n",
    "            stim_RT_1000 = get_RT(stim_1000_df)\n",
    "\n",
    "            # difference between verbal judgements divided by joint variance \n",
    "            # abs(VE1-VE2)/sqrt(stda^2 + std2^2)\n",
    "            std0_250 = answerkey_250[stim0]['std0']\n",
    "            std1_250 = answerkey_250[stim0]['std1']\n",
    "            joint_variance_250 = np.sqrt(std0_250**2 + std1_250**2)\n",
    "            JV_regressor_250 = abs(answerkey_250[stim0]['stimulus_0_avg_estim'] - answerkey_250[stim0]['stimulus_1_avg_estim'])/joint_variance_250\n",
    "\n",
    "            std0_1000 = answerkey_1000[stim0]['std0']\n",
    "            std1_1000 = answerkey_1000[stim0]['std1']\n",
    "            joint_variance_1000 = np.sqrt(std0_1000**2 + std1_1000**2)\n",
    "            JV_regressor_1000 = abs(answerkey_1000[stim0]['stimulus_0_avg_estim'] - answerkey_1000[stim0]['stimulus_1_avg_estim'])/joint_variance_1000\n",
    "            \n",
    "            if stim_acc_250[-1] == 'pos':\n",
    "                VE_depthdifference_250 = abs(answerkey_250[stim0]['stimulus_0_avg_estim'] - answerkey_250[stim0]['stimulus_1_avg_estim'])\n",
    "            else:\n",
    "                VE_depthdifference_250 = -(abs(answerkey_250[stim0]['stimulus_0_avg_estim'] - answerkey_250[stim0]['stimulus_1_avg_estim']))\n",
    "            \n",
    "            if stim_acc_1000[-1] == 'pos':\n",
    "                VE_depthdifference_1000 = abs(answerkey_1000[stim0]['stimulus_0_avg_estim'] - answerkey_1000[stim0]['stimulus_1_avg_estim'])\n",
    "            else:\n",
    "                VE_depthdifference_1000 = -(abs(answerkey_1000[stim0]['stimulus_0_avg_estim'] - answerkey_1000[stim0]['stimulus_1_avg_estim']))\n",
    "            \n",
    "            stimuli_stats[stim0] = {'stimulus_1': other_stim,\n",
    "                                    'accuracy_250': stim_acc_250,\n",
    "                                    'accuracy_1000': stim_acc_1000,\n",
    "                                    'avg_depth': stim_depthbin,\n",
    "                                    'VE_depthdifference_250': VE_depthdifference_250, \n",
    "                                    'VE_depthdifference_1000': VE_depthdifference_1000,\n",
    "                                    'RT_250': stim_RT_250,\n",
    "                                    'RT_1000': stim_RT_1000,\n",
    "                                    'JV_regressor_250': JV_regressor_250,\n",
    "                                    'JV_regressor_1000': JV_regressor_1000}\n",
    "    \n",
    "        except:\n",
    "            print(stim0)\n",
    "\n",
    "    return stimuli_stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "VE_coded_discrim_performance = main_VE_coded_discrim_accuracy(final_discrim, ak_250, ak_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discrimination_results(discrim_performance, duration):\n",
    "    '''\n",
    "    Returns lists of discrimination data results\n",
    "    '''\n",
    "    if duration == 250:\n",
    "        n_VE_estim_diff = [discrim_performance[elem]['VE_depthdifference_250'] for elem in discrim_performance]\n",
    "        n_VE_accuracy = [discrim_performance[elem]['accuracy_250'][0] for elem in discrim_performance]\n",
    "        n_VE_ste = [discrim_performance[elem]['accuracy_250'][-2] for elem in discrim_performance]\n",
    "        n_avg_RT = [discrim_performance[elem]['RT_250'][1] for elem in discrim_performance]\n",
    "        n_avg_RT_ste = [discrim_performance[elem]['RT_250'][-1] for elem in discrim_performance]\n",
    "        n_JV = [discrim_performance[elem]['JV_regressor_250'] for elem in discrim_performance]\n",
    "        \n",
    "    if duration == 1000:\n",
    "        n_VE_estim_diff = [discrim_performance[elem]['VE_depthdifference_1000'] for elem in discrim_performance]\n",
    "        n_VE_accuracy = [discrim_performance[elem]['accuracy_1000'][0] for elem in discrim_performance]\n",
    "        n_VE_ste = [discrim_performance[elem]['accuracy_1000'][-2] for elem in discrim_performance]\n",
    "        n_avg_RT = [discrim_performance[elem]['RT_1000'][1] for elem in discrim_performance]\n",
    "        n_avg_RT_ste = [discrim_performance[elem]['RT_1000'][-1] for elem in discrim_performance]\n",
    "        n_JV = [discrim_performance[elem]['JV_regressor_1000'] for elem in discrim_performance]\n",
    "\n",
    "    n_stim = [elem for elem in discrim_performance]      \n",
    "    \n",
    "    return n_VE_estim_diff, n_VE_accuracy, n_VE_ste, n_avg_RT, n_avg_RT_ste, n_JV, n_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrimination_results_250 = get_discrimination_results(VE_coded_discrim_performance, 250)\n",
    "discrimination_results_1000 = get_discrimination_results(VE_coded_discrim_performance, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(discrimination_results_250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive Performance for VE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VE_performance(stimuli, duration_df, discrimination_performance, duration_answerkey):\n",
    "    '''\n",
    "    Args:\n",
    "        stimuli:  depth discrimination stimuli list \n",
    "        duration_df: VE duration dataframe with ONLY stimulus and list of depth estimates\n",
    "        discrimination performance: dictionary of discrim performance \n",
    "    '''\n",
    "    \n",
    "    VE_Performance = {}\n",
    "            \n",
    "    for im0 in stimuli:\n",
    "        performance = []\n",
    "        # loop through all participants\n",
    "        for subjID in duration_df.subjID.unique():\n",
    "            # filter to just the subjects data df\n",
    "            subjdf = duration_df.loc[duration_df['subjID'] == subjID]\n",
    "            \n",
    "            try:\n",
    "                im0_VE = 'depth_duration_stimuli/' + im0.split('/')[1] + '/' + im0.split('/')[2]\n",
    "                im0_row = subjdf.loc[subjdf['stimulus'] == im0_VE]\n",
    "                im0_estimate = im0_row['depth_estimate'].tolist()[0]\n",
    "\n",
    "                im1 = discrimination_performance[im0]['stimulus_1'][29:]\n",
    "                im1_VE = 'depth_duration_stimuli/' + im1\n",
    "                im1_row = subjdf.loc[subjdf['stimulus'] == im1_VE]\n",
    "                im1_estimate = im1_row['depth_estimate'].tolist()[0]\n",
    "                \n",
    "\n",
    "                if im0_estimate < im1_estimate:\n",
    "                    p_ans = im0.split('/')[-1]\n",
    "                else:\n",
    "                    p_ans = im1.split('/')[-1]\n",
    "                try:\n",
    "                    answerkey_answer = duration_answerkey[im0]['answer']\n",
    "                except:\n",
    "                    answerkey_answer = duration_answerkey['depth_discrimination_stimuli/' + im1]['answer']\n",
    "                if p_ans == answerkey_answer:\n",
    "                    trial_acc = 0 # CORRECT\n",
    "                    performance.append(trial_acc)\n",
    "                else:\n",
    "                    trial_acc = 1 # INCORRECT\n",
    "                    performance.append(trial_acc)\n",
    "            \n",
    "            except:\n",
    "                pass\n",
    "        VE_Performance[im0] = performance\n",
    "\n",
    "    VE_PC = {}\n",
    "\n",
    "    for key in VE_Performance:\n",
    "        performance = VE_Performance[key]\n",
    "        correct_count = performance.count(0)\n",
    "        incorrect_count = performance.count(1)\n",
    "        total = len(performance)\n",
    "        pc = correct_count/total\n",
    "        VE_PC[key] = pc\n",
    "    \n",
    "    return VE_PC\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "VE_performance_250 = VE_performance(discrimination_results_250[-1], r0_250_df, VE_coded_discrim_performance, ak_250)\n",
    "VE_performance_1000 = VE_performance(discrimination_results_1000[-1], r0_1000_df, VE_coded_discrim_performance, ak_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matched Discrimination Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matched_performance(VE_Performance, discrimination_performance, duration):\n",
    "    '''\n",
    "    Args:\n",
    "        VE_performance: dict of VE performance for a specific duration\n",
    "        discrimination_performance: complete discrim performance\n",
    "        duration: int, duration value\n",
    "    Returns:\n",
    "        Trial matched VE and Discrimination performance\n",
    "        List of stimuli \n",
    "        \n",
    "    '''\n",
    "    Discrim_VEmatched_PC = {}\n",
    "    all_stim = []\n",
    "    all_VE_PC = []\n",
    "    all_Discrim_VEmatched_PC = []\n",
    "\n",
    "    for key in VE_Performance:\n",
    "        \n",
    "        im_VE_PC = VE_Performance[key]\n",
    "        if duration == 250:\n",
    "            im_Discrim_PC = discrimination_performance[key]['accuracy_250'][0]\n",
    "        if duration == 1000:\n",
    "            im_Discrim_PC = discrimination_performance[key]['accuracy_1000'][0]\n",
    "        Discrim_VEmatched_PC[key] = [im_VE_PC, im_Discrim_PC]\n",
    "\n",
    "        all_stim.append(key)\n",
    "        all_VE_PC.append(im_VE_PC)\n",
    "        all_Discrim_VEmatched_PC.append(im_Discrim_PC)\n",
    "        \n",
    "    return all_Discrim_VEmatched_PC, all_VE_PC, all_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_discrim_performance_250, m_VE_performance_250, m_stim_250 = matched_performance(VE_performance_250, VE_coded_discrim_performance, 250)\n",
    "m_discrim_performance_1000, m_VE_performance_1000, m_stim_1000 = matched_performance(VE_performance_1000, VE_coded_discrim_performance, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5348837209302325,\n",
       " 0.6585365853658537,\n",
       " 0.9523809523809523,\n",
       " 0.717948717948718,\n",
       " 0.8837209302325582,\n",
       " 0.8809523809523809,\n",
       " 0.95,\n",
       " 0.8,\n",
       " 0.7857142857142857,\n",
       " 0.375,\n",
       " 0.925,\n",
       " 0.1794871794871795,\n",
       " 0.4,\n",
       " 0.9767441860465116,\n",
       " 0.9024390243902439,\n",
       " 0.925,\n",
       " 0.9069767441860465,\n",
       " 0.7142857142857143,\n",
       " 0.825,\n",
       " 0.8,\n",
       " 0.7317073170731707,\n",
       " 0.975,\n",
       " 0.725,\n",
       " 0.9,\n",
       " 0.9534883720930233,\n",
       " 0.6190476190476191,\n",
       " 0.5116279069767442,\n",
       " 0.6190476190476191,\n",
       " 0.5238095238095238,\n",
       " 0.9285714285714286,\n",
       " 0.9047619047619048,\n",
       " 0.6666666666666666,\n",
       " 0.813953488372093,\n",
       " 0.8837209302325582,\n",
       " 0.5853658536585366,\n",
       " 0.5476190476190477,\n",
       " 0.9047619047619048,\n",
       " 0.525,\n",
       " 0.6046511627906976,\n",
       " 0.625,\n",
       " 0.8604651162790697,\n",
       " 0.7368421052631579,\n",
       " 0.6410256410256411,\n",
       " 0.5609756097560976,\n",
       " 0.5384615384615384,\n",
       " 0.7142857142857143,\n",
       " 0.7380952380952381,\n",
       " 0.9069767441860465,\n",
       " 1.0,\n",
       " 0.8048780487804879,\n",
       " 0.9285714285714286,\n",
       " 0.4634146341463415,\n",
       " 0.9302325581395349,\n",
       " 0.46511627906976744,\n",
       " 0.6585365853658537,\n",
       " 0.225,\n",
       " 0.926829268292683,\n",
       " 0.8571428571428571,\n",
       " 0.4878048780487805,\n",
       " 0.95,\n",
       " 0.717948717948718,\n",
       " 0.7073170731707317,\n",
       " 0.8333333333333334,\n",
       " 0.4878048780487805,\n",
       " 0.6666666666666666,\n",
       " 0.8780487804878049,\n",
       " 0.6904761904761905,\n",
       " 1.0,\n",
       " 0.9512195121951219,\n",
       " 0.8571428571428571,\n",
       " 0.38095238095238093,\n",
       " 0.5581395348837209,\n",
       " 0.5,\n",
       " 0.8571428571428571,\n",
       " 0.8571428571428571,\n",
       " 0.8333333333333334,\n",
       " 0.9285714285714286,\n",
       " 0.8571428571428571,\n",
       " 0.525,\n",
       " 0.8292682926829268,\n",
       " 0.125,\n",
       " 0.8095238095238095,\n",
       " 0.7142857142857143,\n",
       " 0.5714285714285714,\n",
       " 0.9,\n",
       " 0.9512195121951219,\n",
       " 0.8333333333333334,\n",
       " 0.8780487804878049,\n",
       " 0.8837209302325582,\n",
       " 0.4473684210526316,\n",
       " 0.7674418604651163,\n",
       " 0.9,\n",
       " 0.725,\n",
       " 0.5853658536585366]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_discrim_performance_250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
