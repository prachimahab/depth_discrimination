{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import random \n",
    "import copy \n",
    "import sqlite3\n",
    "import sys\n",
    "import numpy\n",
    "\n",
    "sequence_count = 0\n",
    "#encapsulates all data points for an object (i.e. image) --> all image characteristics are accessible\n",
    "class Observation:\n",
    "    def __init__(self, subdir, depth):\n",
    "        self.subdir = subdir\n",
    "        self.depth = depth\n",
    "    def getSubdir(self):\n",
    "        return self.subdir\n",
    "    def getDepth(self):\n",
    "        return self.depth \n",
    "    \n",
    "    \n",
    "class Observation_bins: #4 bins organized by depth (1-2m, 2-3m, 3-4m, 4-5m)\n",
    "    def __init__(self):\n",
    "        self.bins = [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [],[], [], [], [],\n",
    "                     [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [],[], [], [], []] #structure that holds organized bins \n",
    "        self.blocks = 4\n",
    "        self.stims_per_block = 24 \n",
    "        self.num_bins = 48\n",
    "        \n",
    "    def addObservation(self, obs): #puts image observations in the correct bin by depth \n",
    "        depth = obs.getDepth()\n",
    "        idx = 0\n",
    "        depth_comparisons = numpy.arange(1,5.1,0.1)\n",
    "        for i in range(len(depth_comparisons)-1):\n",
    "            if depth >=depth_comparisons[i] and depth<depth_comparisons[i+1]:\n",
    "                self.bins[idx].append(obs)\n",
    "                count += 1\n",
    "            idx += 1      \n",
    "        \n",
    "            \n",
    "    #randomly selects an image from a specified bin based on length of bin \n",
    "    def getObservation(self, bin_number): \n",
    "        if len(self.bins[bin_number]) == 0:\n",
    "            sys.exit(\"Bin is empty --> pseudo random solution failed, try again\")\n",
    "\n",
    "        random_number = int(random.random() * len(self.bins[bin_number]))\n",
    "#         print(\"Length of bin\" + str(bin_number)+\":\",len(self.bins[bin_number]) )\n",
    "#         print(\"Random number\", random_number)\n",
    "\n",
    "        return self.bins[bin_number][random_number]\n",
    "    \n",
    "    #removes all observations with the same parent (prevents preview effect)\n",
    "    def _deleteParent(self, sample_parent): #_ i.e. protocol; not called independently \n",
    "        deleted = 0\n",
    "        for i in range(len(self.bins)):  \n",
    "            for j in reversed(range (len(self.bins[i]))): #reversed because length of list shrinks as elements are deleted\n",
    "                parent = self.bins[i][j].getParent() \n",
    "                if parent == sample_parent:\n",
    "\n",
    "                    self.bins[i].pop(j)\n",
    "                    deleted += 1\n",
    "                    \n",
    "        #print(deleted, \"deleted\")\n",
    "        \n",
    "    \n",
    "    #takes in the image name and returns the depth of the target in that image by accessing the object instance associated with that image    \n",
    "    def findObservationDepth(self, stim):\n",
    "        for i in range(len(self.bins)):\n",
    "            for j in reversed(range (len(self.bins[i]))): #reversed because length of list shrinks as elements are deleted\n",
    "                img_subdir = self.bins[i][j].getSubdir()\n",
    "                if img_subdir == stim:\n",
    "                    img_depth = self.bins[i][j].getDepth()\n",
    "                    return img_depth\n",
    "                    \n",
    "                \n",
    "    \n",
    "    \n",
    "    #generates image sequence \n",
    "    def makeSequence(self): \n",
    "        # IMPORTANT: This is a member function. It is called on an instance of the class (clear because self is passed)\n",
    "        # So for example, when x.makeSequence() is called this function is operating within the instance of the class, which is x\n",
    "        # If I want to call other member functions, within this function, they should be called on self NOT x \n",
    "     \n",
    "        # https://docs.python.org/2/library/copy.html; Need an immutable copy function, i.e. deepcopy \n",
    "        bins_backup = copy.deepcopy(self.bins)\n",
    "        s1_stim = []\n",
    "        for i in range(self.blocks): #creates 2d list based on num of blocks\n",
    "            s1_stim.append([])  \n",
    "                \n",
    "        check_dict = {}\n",
    "        \n",
    "\n",
    "        for block in range(self.blocks): #4 blocks in the experiment\n",
    "            for stim_num in range(int(self.stims_per_block/self.num_bins)): \n",
    "                for bin_num in range(self.num_bins):\n",
    "                    #randomly sampled observation \n",
    "                    sample_obs = self.getObservation(bin_num)\n",
    "                    sample_depth = sample_obs.getDepth()\n",
    "                    #call a function to delete that parent from the list of images to prevent duplicates \n",
    "                    self._deleteParent(sample_parent)\n",
    "                    sample_image = sample_obs.getSubdir()\n",
    "                    #adds image filename to sequence list \n",
    "                    s1_stim[block].append(sample_image)\n",
    "                    #add image names to dictionary to ensure no duplicate images are added \n",
    "                    if sample_image not in check_dict:\n",
    "                        check_dict[sample_image] = 1\n",
    "                    else:\n",
    "                        sys.exit(\"Duplicate found: \" + sample_image)\n",
    "                        \n",
    "                    # Duration sequence: 16 images per bin per block per duration \n",
    "                    # Ex. in block 1 there are 16 images from bin1 @ 250 ms \n",
    "                    # Ideally should not be hard coded ... \n",
    "                    \n",
    "                    #first 16 images (stim_num 0-3)\n",
    "                    if stim_num <= 3: \n",
    "                        img_duration[sample_image] = 250\n",
    "                        count250 += 1\n",
    "                    #second 16 images (stim_num 4-7)\n",
    "                    elif stim_num > 3 and stim_num <= 7:\n",
    "                        img_duration[sample_image] = 500\n",
    "                        count500 += 1\n",
    "                    #third 16 images (stim_num 8-11)\n",
    "                    elif stim_num > 7 and stim_num <= 11:\n",
    "                        img_duration[sample_image] = 750\n",
    "                        count750 +=1\n",
    "                    #last 16 images (stim_num 12-15)\n",
    "                    elif stim_num > 11 and stim_num <= 15:\n",
    "                        img_duration[sample_image] = 1000\n",
    "                        count1000 += 1\n",
    "                        \n",
    "\n",
    "        #randomly shuffle the elements of each block \n",
    "        for block in s1_stim:\n",
    "            random.shuffle(block)\n",
    "            \n",
    "        #generate duration sequence based on the SHUFFLED order of selected images \n",
    "        s1_duration_seq = []\n",
    "        for i in range(self.blocks): #creates 2d list based on num of blocks\n",
    "            s1_duration_seq.append([])\n",
    "            \n",
    "        for block in range(self.blocks):\n",
    "            for img in s1_stim[block]:\n",
    "                duration = img_duration[img]\n",
    "                s1_duration_seq[block].append(duration)\n",
    "                \n",
    "        self.bins = bins_backup #resets the main bins list back to the original for the next sequence \n",
    "        \n",
    "                \n",
    "        # Database structure \n",
    "\n",
    "        # sequence_A = [(sequence_A, img1, bin1-2, 500), (sequence_A, img2, bin4-5, 250)...]\n",
    "        # TUPLE = (sequence name, img name, duration, order of presentation = 1 if the first image, depth )\n",
    "        entry = []\n",
    "        for block in s1_stim:\n",
    "            for stim in block:\n",
    "                 ## finding the number of presentation of the image in the overall sequence ##\n",
    "                block_index = s1_stim.index(block)\n",
    "                index_in_block = block.index(stim) + 1 #plus one so that indices start at 1 not zero \n",
    "                overall_index = len(block)*block_index + index_in_block\n",
    "                \n",
    "                #indexes to find corresponding duration for the image \n",
    "                duration = s1_duration_seq[block_index][index_in_block-1]    \n",
    "                \n",
    "                depth = self.findObservationDepth(stim)\n",
    "                img_list = ['placeholder_sequence_name', stim, duration, overall_index, depth]\n",
    "                #convert into tuple later once sequence name is known\n",
    "                entry.append(img_list)\n",
    "                \n",
    "        \n",
    "        # Removes images that were sampled in s1_stim (current sequence)\n",
    "        count = 0\n",
    "        for i in range(len(self.bins)):\n",
    "            for j in reversed(range (len(self.bins[i]))): #reversed because length of list shrinks as elements are deleted\n",
    "                subdir = self.bins[i][j].getSubdir()                    \n",
    "                for block in s1_stim:\n",
    "                    if subdir in block:\n",
    "                        self.bins[i].pop(j)\n",
    "                        count += 1\n",
    "                        \n",
    "        #print([count250, count500, count750, count1000])\n",
    "        \n",
    "        return s1_stim, s1_duration_seq, entry\n",
    "    \n",
    "               \n",
    "def getTargetInfo(directory):\n",
    "    \"\"\"\n",
    "    Indexes into the json file of each image and recursively extracts image characteristics\n",
    "    All object (target image) instances are added to obs_bins (main list of all images)\n",
    "    Args: \n",
    "        directory = path to cleaned stimuli folder\n",
    "    Returns:\n",
    "        obs_bins = instance of Observation_bins class that has depth_ob (instance) for every target image\n",
    "    \"\"\"\n",
    "    \n",
    "    obs_list = [] #[parent, filepath, depth] for all of the images \n",
    "    obs_bins = Observation_bins() #instance of the class \n",
    "    for subdir, dirs, files in os.walk(directory): #recursively goes through all the folders \n",
    "        for file in files:\n",
    "            filepath = subdir + os.sep + file\n",
    "            if \".ipynb_checkpoints\" not in str(subdir):\n",
    "                if filepath.endswith(\".json\"):\n",
    "                    output_json = json.load(open(filepath)) #loads each data.json file\n",
    "                    objects = output_json['objects'] \n",
    "                    for obj in objects:\n",
    "                        cp = obj[\"crossing_point\"]\n",
    "                        cp = cp[0] #indexes to the dict\n",
    "                        depth = cp['depth']\n",
    "\n",
    "                        depth_ob = Observation(subdir, depth) #creating an instance\n",
    "                        obs_bins.addObservation(depth_ob) #adding one object to another (an observation to the bins list)\n",
    "    return obs_bins        \n",
    "        \n",
    "# obs_bins = getTargetInfo() #called on directory where images are stored \n",
    "\n",
    "# obs_bins = getTargetInfo(\"/Users/prachimahableshwarkar/Documents/GW/Depth_MTurk/depth_duration_MTurk/depth_duration_stimuli\")\n",
    "\n",
    "# #### MAIN PROGRAM BEGINS HERE #### \n",
    "  \n",
    "# def generateFourSequences(obs_bins, mother_group):\n",
    "#     \"\"\"\n",
    "#     After a sequence is made, those target images (not parent) are removed from the master list \n",
    "#     Once 4 sequences can be made in this way because of stimuli constraints\n",
    "#     NOTE: sometimes 4 sequences might not work because of the variability of random sampling - in that case exception is thrown\n",
    "#     \"\"\"\n",
    "#     #list of the names of the sequences \n",
    "#     #Mother group is used now since sequences are made in groups of 4\n",
    "#     #seq_names = [mother_group+\"1\", mother_group+\"2\", mother_group+\"3\", mother_group+\"4\"]\n",
    "#     seq_names = [mother_group+\"1\"]\n",
    "\n",
    "#     lst_seq = []\n",
    "#     for i in range(len(seq_names)): #generate 4 sequences, add entry to list of sequences\n",
    "#         output = obs_bins.makeSequence()\n",
    "#         entry = output[2]\n",
    "#         lst_seq.append(entry)\n",
    "\n",
    "#     entry_list = [] #list of image tuples for all trials in all sequences\n",
    "#     for seq in lst_seq:\n",
    "#         for item in seq:\n",
    "#             index = lst_seq.index(seq)\n",
    "#             item[0] = \"sequence_\" + seq_names[index] #replaces \"placeholder sequence name\" with actual name \n",
    "#             item = tuple(item) #converts list to tuple so it can be added to the database \n",
    "#             entry_list.append(item)\n",
    "                        \n",
    "            \n",
    "#     return entry_list\n",
    "\n",
    "\n",
    "# class Group:\n",
    "#     def __init__(self, sequences):\n",
    "#         self.sequences = sequences #listofGroupSequences --> [(), (), ...] --> tuples for the trials for all four sequences of that group\n",
    "    \n",
    "#     def getNumParents(self):\n",
    "#         \"\"\"\n",
    "#         Member function of Group class \n",
    "#         Returns number of unique parents in the group \n",
    "#         \"\"\"\n",
    "        \n",
    "#         lst_group_parents = []\n",
    "#         for trial in self.sequences:\n",
    "#             folder_path = trial[1] #path to parent folder\n",
    "#             fp_split = folder_path.split(\"/\")\n",
    "#             folder = fp_split[-1]\n",
    "#             folder_split = folder.split(\"_\")\n",
    "#             parent = folder_split[0] #isolated parent image name\n",
    "#             lst_group_parents.append(parent)\n",
    "                \n",
    "# #         print(\"Parent List length: \", len(lst_group_parents)) #should be 256 * 4 = 1024\n",
    "        \n",
    "#         set_groupParents = set(lst_group_parents) #convert to set so duplicates are removed\n",
    "# #         print(\"Parent Set length: \", len(set_groupParents)) \n",
    "\n",
    "#         return len(set_groupParents) #total number of unique parents in the group\n",
    "    \n",
    "#     def returnGroup(self):\n",
    "#         \"\"\"\n",
    "#         Member function of Group class \n",
    "#         Returns the group (4 sequences) in its original form \n",
    "#         \"\"\"\n",
    "#         return self.sequences \n",
    "        \n",
    "\n",
    "# def findBestGroup(stimuli_path):\n",
    "#     \"\"\"\n",
    "#     Generates groups of 4 sequences \n",
    "#     Returns the group that has the maximum amount of unique parent images \n",
    "\n",
    "#     \"\"\"\n",
    "#     print(\"Testing group seq generation\")\n",
    "    \n",
    "#     complete_entry = []\n",
    "        \n",
    "#     group_names = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\" ,\"M\", \n",
    "#                    \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]    \n",
    "    \n",
    "    \n",
    "#     for name in group_names:\n",
    "#         obs_bins = getTargetInfo(stimuli_path) #resets obs_bins after 4 sequences are made \n",
    "#         listofGroupSequences = generateFourSequences(obs_bins, name) #1D list of tuples \n",
    "#         group_entry = Group(listofGroupSequences) #Group is a class \n",
    "#         # group_entry is an instance of the class \n",
    "#         complete_entry.append(group_entry) #list of group objects \n",
    "    \n",
    "#     #https://www.agnosticdev.com/content/how-sort-objects-custom-property-python\n",
    "#     #sort complete_entry based on number of parents in each group \n",
    "#     #getNumParents() is a member function\n",
    "#     # lambda specifies that I am running a function on each element\n",
    "#     # it loops through all elements (groups) of complete_entry (element = x)\n",
    "#     # reverse = True --> maximum to minimum \n",
    "    \n",
    "#     complete_entry.sort(key=lambda x: x.getNumParents(), reverse=True)\n",
    "    \n",
    "#     for group in complete_entry:\n",
    "#         print(\"Number of Unique Parents in Group:\" + str(group.getNumParents()))\n",
    "        \n",
    "#     max_group = complete_entry[0].returnGroup() #0 because complete_entry is ordered max --> min\n",
    "        \n",
    "#     return max_group \n",
    "\n",
    "# def foo(stimulus_path):\n",
    "#     \"\"\"\n",
    "#     Restarts findBestGroup after exception (random sequence solution fails)\n",
    "#     Args:\n",
    "#         stimulus_path = SUN-RGBD cleaned stimuli folder \n",
    "#     Returns:\n",
    "#         Group of sequences that has the maximum number of parent images\n",
    "#         - list of trial tuples for four sequences (ex. a1, a2, a3, a4)\n",
    "#         - this list should be inputted to database \n",
    "#     \"\"\"\n",
    "#     while True:\n",
    "#         try:\n",
    "#             bestGroup = findBestGroup(stimulus_path)\n",
    "#             return bestGroup\n",
    "#         except:\n",
    "#             pass\n",
    "#         else:\n",
    "#             break\n",
    "            \n",
    "# path = \"/Users/prachi/Documents/depth_duration/mar3_depthDuration_stimuli/targetImages_kinect2data_subset\"\n",
    "# Group_max_parents = foo(path)\n",
    "# # print(Group_max_parents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import random \n",
    "import copy \n",
    "import sqlite3\n",
    "import sys\n",
    "import numpy as np \n",
    "\n",
    "class Observation:\n",
    "    def __init__(self, subdir, depth):\n",
    "        self.subdir = subdir\n",
    "        self.depth = depth\n",
    "    def getSubdir(self):\n",
    "        return self.subdir\n",
    "    def getDepth(self):\n",
    "        return self.depth \n",
    "    \n",
    "    \n",
    "class Observation_bins: #4 bins organized by depth (1-2m, 2-3m, 3-4m, 4-5m)\n",
    "    def __init__(self):\n",
    "        self.bins = [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [],[], [], [], [],\n",
    "                     [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [],[], [], [], []] #structure that holds organized bins \n",
    "        self.blocks = 4\n",
    "        self.stims_per_block = 24 \n",
    "        self.num_bins = 48\n",
    "        \n",
    "    def addObservation(self, obs): #puts image observations in the correct bin by depth \n",
    "        depth = obs.getDepth()\n",
    "        idx = 0\n",
    "        depth_comparisons = np.arange(1,5.1,0.2)\n",
    "        for i in range(len(depth_comparisons)-1):\n",
    "            if depth >=depth_comparisons[i] and depth<depth_comparisons[i+1]:\n",
    "                self.bins[idx].append(obs)\n",
    "            idx += 1      \n",
    "            \n",
    "    def getBinObservations(self, bin_number): \n",
    "        try:\n",
    "            print(self.bins[bin_number][0])\n",
    "        except:\n",
    "            print(None)\n",
    "        return self.bins[bin_number]\n",
    "    \n",
    "    #takes in the image name and returns the depth of the target in that image by accessing the object instance associated with that image    \n",
    "    def findObservationDepth(self, stim):\n",
    "        for i in range(len(self.bins)):\n",
    "            for j in reversed(range (len(self.bins[i]))): #reversed because length of list shrinks as elements are deleted\n",
    "                img_subdir = self.bins[i][j].getSubdir()\n",
    "                if img_subdir == stim:\n",
    "                    img_depth = self.bins[i][j].getDepth()\n",
    "                    return img_depth\n",
    "                        \n",
    "    #generates image sequence \n",
    "    def makeSequences(self): \n",
    "        # IMPORTANT: This is a member function. It is called on an instance of the class (clear because self is passed)\n",
    "        # So for example, when x.makeSequence() is called this function is operating within the instance of the class, which is x\n",
    "        # If I want to call other member functions, within this function, they should be called on self NOT x \n",
    "     \n",
    "        # https://docs.python.org/2/library/copy.html; Need an immutable copy function, i.e. deepcopy \n",
    "        bins_backup = copy.deepcopy(self.bins)\n",
    "        s1_stim = []\n",
    "        for i in range(self.blocks): #creates 2d list based on num of blocks\n",
    "            s1_stim.append([])  \n",
    "                \n",
    "        check_dict = {}\n",
    "\n",
    "        for block in range(self.blocks): #4 blocks in the experiment\n",
    "            for bin_num in range(self.num_bins):\n",
    "                bin_obs = self.getBinObservations(bin_num)\n",
    "                \n",
    "        return None \n",
    "#                 #randomly sampled observation \n",
    "#                 sample_obs = self.getObservation(bin_num)\n",
    "#                 sample_depth = sample_obs.getDepth()\n",
    "#                 #call a function to delete that parent from the list of images to prevent duplicates \n",
    "#                 self._deleteParent(sample_parent)\n",
    "#                 sample_image = sample_obs.getSubdir()\n",
    "#                 #adds image filename to sequence list \n",
    "#                 s1_stim[block].append(sample_image)\n",
    "#                 #add image names to dictionary to ensure no duplicate images are added \n",
    "#                 if sample_image not in check_dict:\n",
    "#                     check_dict[sample_image] = 1\n",
    "#                 else:\n",
    "#                     sys.exit(\"Duplicate found: \" + sample_image)\n",
    "     \n",
    "\n",
    "#         #randomly shuffle the elements of each block \n",
    "#         for block in s1_stim:\n",
    "#             random.shuffle(block)\n",
    "            \n",
    "#         #generate duration sequence based on the SHUFFLED order of selected images \n",
    "#         s1_duration_seq = []\n",
    "#         for i in range(self.blocks): #creates 2d list based on num of blocks\n",
    "#             s1_duration_seq.append([])\n",
    "            \n",
    "#         for block in range(self.blocks):\n",
    "#             for img in s1_stim[block]:\n",
    "#                 duration = img_duration[img]\n",
    "#                 s1_duration_seq[block].append(duration)\n",
    "                \n",
    "#         self.bins = bins_backup #resets the main bins list back to the original for the next sequence \n",
    "        \n",
    "                \n",
    "#         # Database structure \n",
    "\n",
    "#         # sequence_A = [(sequence_A, img1, bin1-2, 500), (sequence_A, img2, bin4-5, 250)...]\n",
    "#         # TUPLE = (sequence name, img name, duration, order of presentation = 1 if the first image, depth )\n",
    "#         entry = []\n",
    "#         for block in s1_stim:\n",
    "#             for stim in block:\n",
    "#                  ## finding the number of presentation of the image in the overall sequence ##\n",
    "#                 block_index = s1_stim.index(block)\n",
    "#                 index_in_block = block.index(stim) + 1 #plus one so that indices start at 1 not zero \n",
    "#                 overall_index = len(block)*block_index + index_in_block\n",
    "                \n",
    "#                 #indexes to find corresponding duration for the image \n",
    "#                 duration = s1_duration_seq[block_index][index_in_block-1]    \n",
    "                \n",
    "#                 depth = self.findObservationDepth(stim)\n",
    "#                 img_list = ['placeholder_sequence_name', stim, duration, overall_index, depth]\n",
    "#                 #convert into tuple later once sequence name is known\n",
    "#                 entry.append(img_list)\n",
    "                \n",
    "        \n",
    "#         # Removes images that were sampled in s1_stim (current sequence)\n",
    "#         count = 0\n",
    "#         for i in range(len(self.bins)):\n",
    "#             for j in reversed(range (len(self.bins[i]))): #reversed because length of list shrinks as elements are deleted\n",
    "#                 subdir = self.bins[i][j].getSubdir()                    \n",
    "#                 for block in s1_stim:\n",
    "#                     if subdir in block:\n",
    "#                         self.bins[i].pop(j)\n",
    "#                         count += 1\n",
    "                        \n",
    "#         #print([count250, count500, count750, count1000])\n",
    "        \n",
    "#         return s1_stim, s1_duration_seq, entry\n",
    "    \n",
    "               \n",
    "def getSubdirTargetInfo(directory):\n",
    "    \"\"\"\n",
    "    Indexes into the json file of each image and recursively extracts image characteristics\n",
    "    All object (target image) instances are added to obs_bins (main list of all images)\n",
    "    Args: \n",
    "        directory = path to cleaned stimuli folder\n",
    "    Returns:\n",
    "        obs_bins = instance of Observation_bins class that has depth_ob (instance) for every target image\n",
    "    \"\"\"\n",
    "    obs = {}\n",
    "    for folder in os.listdir(directory): #recursively goes through all the folders   \n",
    "        for file in os.listdir(directory + '/' + folder):\n",
    "            filepath = directory + '/' + folder + '/' + file\n",
    "            if \".ipynb_checkpoints\" not in str(filepath):\n",
    "                if filepath.endswith(\".json\"):\n",
    "                    output_json = json.load(open(filepath)) #loads each data.json file\n",
    "                    objects = output_json['objects'] \n",
    "                    for obj in objects:\n",
    "                        cp = obj[\"crossing_point\"]\n",
    "                        cp = cp[0] #indexes to the dict\n",
    "                        depth = cp['depth']\n",
    "                        obs[folder] = depth\n",
    "\n",
    "    return obs\n",
    "                    \n",
    "########## MAIN PROGRAM BEGINS HERE ########## \n",
    "  \n",
    "def generateSequences(obs_bins, mother_group):\n",
    "    #list of the names of the sequences \n",
    "    \n",
    "    seq_names = [mother_group+\"1\", mother_group+\"2\", mother_group+\"3\", mother_group+\"4\", mother_group+\"5\", mother_group+\"6\"]\n",
    "\n",
    "    output = obs_bins.makeSequences()\n",
    "    entry = output[2] # list of sequences \n",
    "    \n",
    "    sequences = []\n",
    "    for i in range(len(entry)):\n",
    "        entry_list = [] #list of image tuples for all trials in all sequences\n",
    "        for item in entry[i]:\n",
    "            item[0] = \"sequence_\" + seq_names[i]\n",
    "            item = tuple(item)\n",
    "            entry_list.append(item)\n",
    "        sequences.append(entry_list)\n",
    "            \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_bins = getSubdirTargetInfo(path)\n",
    "\n",
    "obs_bins.makeSequences()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import random \n",
    "import copy \n",
    "import sqlite3\n",
    "import sys\n",
    "import numpy as np \n",
    "from itertools import permutations  \n",
    "import itertools\n",
    "\n",
    "def getSubdirTargetInfo(directory):\n",
    "    \"\"\"\n",
    "    Indexes into the json file of each image and recursively extracts image characteristics\n",
    "    All object (target image) instances are added to obs_bins (main list of all images)\n",
    "    Args: \n",
    "        directory = path to cleaned stimuli folder\n",
    "    Returns:\n",
    "        obs_bins = instance of Observation_bins class that has depth_ob (instance) for every target image\n",
    "    \"\"\"\n",
    "    obs = {}\n",
    "    for folder in os.listdir(directory): #recursively goes through all the folders\n",
    "        if folder != '.DS_Store':\n",
    "            for file in os.listdir(directory + '/' + folder):\n",
    "                filepath = directory + '/' + folder + '/' + file\n",
    "                if \".ipynb_checkpoints\" not in str(filepath):\n",
    "                    if filepath.endswith(\".json\"):\n",
    "                        output_json = json.load(open(filepath)) #loads each data.json file\n",
    "                        objects = output_json['objects'] \n",
    "                        for obj in objects:\n",
    "                            cp = obj[\"crossing_point\"]\n",
    "                            cp = cp[0] #indexes to the dict\n",
    "                            depth = cp['depth']\n",
    "                            obs[folder] = depth\n",
    "\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/prachi/Documents/depth_duration/mar3_depthDuration_stimuli/final_stimuli'\n",
    "\n",
    "# path = '/Users/prachimahableshwarkar/Documents/GW/Depth_MTurk/depth_duration_MTurk/depth_duration_stimuli'\n",
    "observations = getSubdirTargetInfo(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "# sort observations by increasing depth (dict value)\n",
    "sorted_tuples = sorted(observations.items(), key=operator.itemgetter(1))\n",
    "sorted_dict = {k: v for k, v in sorted_tuples}\n",
    "\n",
    "# create groups of 4 from low to high depth --> 48 groups total \n",
    "grouped_observations = [sorted_tuples[i*4:(i*4)+4] for i in range(48)]\n",
    "len(grouped_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('002272_2014-06-28_18-53-56_260595134347_rgbf000067-resize_2', 1.138),\n",
       " ('002509_2014-06-24_13-19-22_094959634447_rgbf000077-resize_0', 1.3065),\n",
       " ('000483_2014-06-09_20-41-45_260595134347_rgbf000116-resize_4',\n",
       "  1.3370000000000002),\n",
       " ('000109_2014-05-14_23-41-52_260595134347_rgbf000035-resize_9', 1.3545)]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_observations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "6 (48,)\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "import random\n",
    "\n",
    "# tuples represent the indeces of images within the 4 image group \n",
    "combinations = list(combinations([0,1,2,3],2))\n",
    "bins_combinations = [copy.deepcopy(combinations),copy.deepcopy(combinations),copy.deepcopy(combinations),\n",
    "                     copy.deepcopy(combinations),copy.deepcopy(combinations),copy.deepcopy(combinations),\n",
    "                     copy.deepcopy(combinations),copy.deepcopy(combinations),copy.deepcopy(combinations),\n",
    "                     copy.deepcopy(combinations),copy.deepcopy(combinations),copy.deepcopy(combinations),\n",
    "                     copy.deepcopy(combinations),copy.deepcopy(combinations),copy.deepcopy(combinations),\n",
    "                     copy.deepcopy(combinations),copy.deepcopy(combinations),copy.deepcopy(combinations),\n",
    "                     copy.deepcopy(combinations),copy.deepcopy(combinations),copy.deepcopy(combinations),\n",
    "                     copy.deepcopy(combinations),copy.deepcopy(combinations),copy.deepcopy(combinations),\n",
    "                     copy.deepcopy(combinations),copy.deepcopy(combinations),copy.deepcopy(combinations),\n",
    "                     copy.deepcopy(combinations),copy.deepcopy(combinations),copy.deepcopy(combinations),\n",
    "                     copy.deepcopy(combinations),copy.deepcopy(combinations),copy.deepcopy(combinations),\n",
    "                     copy.deepcopy(combinations),copy.deepcopy(combinations),copy.deepcopy(combinations),\n",
    "                     copy.deepcopy(combinations),copy.deepcopy(combinations),copy.deepcopy(combinations),\n",
    "                     copy.deepcopy(combinations),copy.deepcopy(combinations),copy.deepcopy(combinations),\n",
    "                     copy.deepcopy(combinations),copy.deepcopy(combinations),copy.deepcopy(combinations),\n",
    "                     copy.deepcopy(combinations),copy.deepcopy(combinations),copy.deepcopy(combinations)]\n",
    "print(len(bins_combinations))\n",
    "\n",
    "sequences = np.array([[None]*48]*6, dtype=object)\n",
    "print(len(sequences), sequences[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in range(6): # 6 sequences total to completely cover the set of comparisons \n",
    "    for i in range(len(bins_combinations)): # 48 bins\n",
    "        # randomly select an image index combo \n",
    "        random_combo = random.choice(bins_combinations[i])\n",
    "        random_combo_idx = bins_combinations[i].index(random_combo)\n",
    "        # remove the selected image index combo \n",
    "        del bins_combinations[i][random_combo_idx]\n",
    "        # add selected combo to sequence[seq]\n",
    "        sequences[seq][i]= random_combo\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48,)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Images based on Sequence\n",
    "\n",
    "#### Create image order rotation sequence too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = '/Users/prachi/Documents/depth_duration/depth_discrimination/discrimination_sequences'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_dictionaries = []\n",
    "rotated_sequence_dictionaries = [] # order of images is flipped\n",
    "seq_names = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5']\n",
    "durations = [250, 1000, 250, 1000, 250, 1000, 250, 1000, 250, 1000,\n",
    "             250, 1000, 250, 1000, 250, 1000, 250, 1000, 250, 1000,\n",
    "             250, 1000, 250, 1000, 250, 1000, 250, 1000, 250, 1000,\n",
    "             250, 1000, 250, 1000, 250, 1000, 250, 1000, 250, 1000,\n",
    "             250, 1000, 250, 1000, 250, 1000, 250, 1000]\n",
    "# shuffle durations \n",
    "random.shuffle(durations)\n",
    "\n",
    "for i in range(len(sequences)):\n",
    "    seq = [] \n",
    "    rotated_seq = []\n",
    "    sequence_name = seq_names[i]\n",
    "    rotated_seq_name = seq_names[i] + '_rotated' # order rotated\n",
    "    num = 0\n",
    "    for trial in sequences[i]:\n",
    "        img0_index = trial[0]\n",
    "        img1_index = trial[1]\n",
    "        dict_trial = {}\n",
    "        dict_trial[\"sequence\"] = sequence_name\n",
    "        dict_trial[\"duration\"] = durations[num]\n",
    "        dict_trial[\"depth_0\"] = grouped_observations[num][img0_index][1]\n",
    "        dict_trial[\"depth_1\"] = grouped_observations[num][img1_index][1]\n",
    "\n",
    "        targetimg_0 = grouped_observations[num][img0_index][0]\n",
    "        targetimg_1 = grouped_observations[num][img1_index][0]\n",
    "        # this has to be the path on the server\n",
    "        targetimg_0_path = \"depth_discrimination_stimuli/\" + targetimg_0 + '/' + targetimg_0 + '-target.png'\n",
    "        targetimg_1_path = \"depth_discrimination_stimuli/\" + targetimg_1 + '/' + targetimg_1 + '-target.png'\n",
    "\n",
    "        dict_trial[\"image_path_target_0\"] = targetimg_0_path\n",
    "        dict_trial[\"image_path_target_1\"] = targetimg_1_path\n",
    "\n",
    "        dict_trial[\"mask_path\"] = \"masks/mask_\" + str(num) + \".jpg\"\n",
    "        dict_trial[\"fixation_path\"] = \"fixation.jpg\"\n",
    "\n",
    "        seq.append(dict_trial)\n",
    "        ###################### Rotated sequence ######################\n",
    "        rotated_dict_trial = {}\n",
    "        rotated_dict_trial[\"sequence\"] = rotated_seq_name\n",
    "        rotated_dict_trial[\"duration\"] = durations[num]\n",
    "        rotated_dict_trial[\"depth_0\"] = grouped_observations[num][img1_index][1]\n",
    "        rotated_dict_trial[\"depth_1\"] = grouped_observations[num][img0_index][1]\n",
    "\n",
    "        r_targetimg_0 = grouped_observations[num][img1_index][0]\n",
    "        r_targetimg_1 = grouped_observations[num][img0_index][0]\n",
    "        # this has to be the path on the server\n",
    "        r_targetimg_0_path = \"depth_discrimination_stimuli/\" + r_targetimg_1 + '/' + r_targetimg_1 + '-target.png'\n",
    "        r_targetimg_1_path = \"depth_discrimination_stimuli/\" + r_targetimg_0 + '/' + r_targetimg_0 + '-target.png'\n",
    "\n",
    "        rotated_dict_trial[\"image_path_target_0\"] = r_targetimg_1_path\n",
    "        rotated_dict_trial[\"image_path_target_1\"] = r_targetimg_0_path\n",
    "\n",
    "        rotated_dict_trial[\"mask_path\"] = \"masks/mask_\" + str(num) + \".jpg\"\n",
    "        rotated_dict_trial[\"fixation_path\"] = \"fixation.jpg\"\n",
    "\n",
    "        rotated_seq.append(rotated_dict_trial)\n",
    "        \n",
    "        num += 1\n",
    "    \n",
    "    # shuffle the order of trials so that trials are not in order of increasing depth \n",
    "    # use the same random seed for sequence & it's rotation so trials match in images \n",
    "    random.Random(i).shuffle(seq)\n",
    "    random.Random(i).shuffle(rotated_seq)\n",
    "\n",
    "    # reshuffle durations so that each sequence has a different duration order \n",
    "    random.shuffle(durations)\n",
    "    \n",
    "    sequence_dictionaries.append(seq)\n",
    "    rotated_sequence_dictionaries.append(rotated_seq)\n",
    "\n",
    "    \n",
    "for sequence in sequence_dictionaries:\n",
    "    name = sequence[0][\"sequence\"]\n",
    "    path = destination + '/' + name + '.json'\n",
    "    # creates json file for the sequence \n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(sequence , f)  \n",
    "        \n",
    "for rotated_sequence in rotated_sequence_dictionaries:\n",
    "    rotated_name = rotated_sequence[0][\"sequence\"]\n",
    "    rotated_path = destination + '/' + rotated_name + '.json'\n",
    "    # creates json file for the sequence \n",
    "    with open(rotated_path, 'w') as f:\n",
    "        json.dump(rotated_sequence , f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate Sequence by Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "def load_master_sequence(jsonpath):\n",
    "    return json.load(open(jsonpath))\n",
    "\n",
    "def rotate_sequence(previous_seq):\n",
    "    \"\"\"\n",
    "    Rotates each trial's duration assignment based on previous sequence \n",
    "    250 --> 1000\n",
    "    1000 --> 250\n",
    "    \"\"\"\n",
    "    rotated = previous_seq\n",
    "    for i in range(len(previous_seq)):\n",
    "        duration = previous_seq[i]['duration']\n",
    "        if duration == 1000:\n",
    "            new_duration = 250\n",
    "        else:\n",
    "            new_duration = 1000\n",
    "        rotated[i]['duration'] = new_duration\n",
    "        \n",
    "    return rotated\n",
    "\n",
    "def create_duration_rotations(jsonpath, exit, name):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        jsonpath = path to master json created through sequence pipeline\n",
    "        exit = destination path for new jsons \n",
    "        name = i.e. V1 \n",
    "    \n",
    "    Creates sequences rotated by duration so that all images in the master sequence are seen at each duration\n",
    "    (across participants)\n",
    "        \n",
    "    \"\"\"\n",
    "    master = load_master_sequence(jsonpath)\n",
    "    \n",
    "    r = rotate_sequence(master)\n",
    "    r_path = exit + '/' + name + '_dr.json' # duration rotated sequence\n",
    "    #creates json file for the sequence \n",
    "    with open(r_path, 'w') as f:\n",
    "        json.dump(r , f)\n",
    "\n",
    "        \n",
    "def main_seq_rotations(json_folderpath, exit):\n",
    "    \"\"\"\n",
    "    Create rotated sequence for each sequence in the folder\n",
    "    \"\"\"\n",
    "    for file in os.listdir(json_folderpath):\n",
    "        name = file.split(\".\")[0]\n",
    "        jsonpath = json_folderpath + \"/\" + file\n",
    "        try:\n",
    "            create_duration_rotations(jsonpath, exit, name)\n",
    "        except:\n",
    "            print(\"Failed to create json rotations for: \", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
