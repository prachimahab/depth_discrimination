{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAC Discrimination Analysis: \n",
    "\n",
    "# Within Participants who have seen both discrimination images @ the same duration in the Verbal Judgement experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy \n",
    "import scipy.stats as stats\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Target at Center Verbal Judgement Data \n",
    "\n",
    "TAC_data_path = '/Users/pmahableshwarkar/Documents/Depth_Project/depth_duration_analysis/TAC_data'\n",
    "\n",
    "raw_TAC_250 = pd.read_csv(TAC_data_path + '/raw_250_data.csv')\n",
    "raw_TAC_500 = pd.read_csv(TAC_data_path + '/raw_500_data.csv')\n",
    "raw_TAC_750 = pd.read_csv(TAC_data_path + '/raw_750_data.csv')\n",
    "raw_TAC_1000 = pd.read_csv(TAC_data_path + '/raw_1000_data.csv')\n",
    "\n",
    "n_TAC_250 = pd.read_csv(TAC_data_path + '/normalized_250_data.csv')\n",
    "n_TAC_500 = pd.read_csv(TAC_data_path + '/normalized_500_data.csv')\n",
    "n_TAC_750 = pd.read_csv(TAC_data_path + '/normalized_750_data.csv')\n",
    "n_TAC_1000 = pd.read_csv(TAC_data_path + '/normalized_1000_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one TAC Discrimination json sequence \n",
    "# all sequences have the same image combinations for the trials, duration and order is counterbalanced \n",
    "\n",
    "discrim_json0_path = '/Users/pmahableshwarkar/Documents/Depth_Project/depth_discrimination/TAC_depth_discrimination_MTurk/discrim_jsons/v2_shuffled_g0_dr.json'\n",
    "\n",
    "with open(discrim_json0_path) as f:\n",
    "    discrim_json0 = json.load(f)\n",
    "    \n",
    "discrim_image_combos = []\n",
    "for trial in discrim_json0:\n",
    "    combo = (trial['image_path_target_0'][29:], trial['image_path_target_1'][29:])\n",
    "    discrim_image_combos.append(combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary where key is one of the images in a discimrination trial, \n",
    "# and the value will be a list of all the subjects that saw both images at the same duration\n",
    "\n",
    "discrim_trial_subjects_250 = {}\n",
    "for combo in discrim_image_combos:\n",
    "    discrim_trial_subjects_250[combo[0]] = []\n",
    "    \n",
    "# find subjects that saw BOTH discrimination trials at 250 ms\n",
    "\n",
    "subjs_250 = raw_TAC_250.subjID.unique()\n",
    "\n",
    "for subj in subjs_250:\n",
    "    subj_df = raw_TAC_250.loc[raw_TAC_250['subjID'] == subj]\n",
    "    for combo in discrim_image_combos:\n",
    "        img0_path = 'depth_duration_stimuli/' + combo[0]\n",
    "        dimg0_row = subj_df.loc[subj_df['stimulus'] == img0_path]\n",
    "        \n",
    "        img1_path = 'depth_duration_stimuli/' + combo[1]\n",
    "        dimg1_row = subj_df.loc[subj_df['stimulus'] == img1_path]\n",
    "        \n",
    "        \n",
    "        if len(dimg0_row) == 1:\n",
    "             if len(dimg1_row) == 1:\n",
    "                if subj not in discrim_trial_subjects_250[combo[0]]:\n",
    "                    discrim_trial_subjects_250[combo[0]].append(subj)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "17\n",
      "14\n",
      "11\n",
      "0\n",
      "11\n",
      "15\n",
      "11\n",
      "0\n",
      "13\n",
      "13\n",
      "12\n",
      "0\n",
      "10\n",
      "13\n",
      "7\n",
      "12\n",
      "5\n",
      "15\n",
      "0\n",
      "9\n",
      "12\n",
      "15\n",
      "11\n",
      "16\n",
      "0\n",
      "11\n",
      "14\n",
      "7\n",
      "0\n",
      "10\n",
      "16\n",
      "13\n",
      "8\n",
      "0\n",
      "11\n",
      "14\n",
      "0\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for key in discrim_trial_subjects_250:\n",
    "    print(len(discrim_trial_subjects_250[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary where key is one of the images in a discimrination trial, \n",
    "# and the value will be a list of all the subjects that saw both images at the same duration\n",
    "\n",
    "discrim_trial_subjects_1000 = {}\n",
    "for combo in discrim_image_combos:\n",
    "    discrim_trial_subjects_1000[combo[0]] = []\n",
    "    \n",
    "# find subjects that saw BOTH discrimination trials at 250 ms\n",
    "\n",
    "subjs_1000 = raw_TAC_1000.subjID.unique()\n",
    "\n",
    "for subj in subjs_1000:\n",
    "    subj_df = raw_TAC_1000.loc[raw_TAC_1000['subjID'] == subj]\n",
    "    for combo in discrim_image_combos:\n",
    "        img0_path = 'depth_duration_stimuli/' + combo[0]\n",
    "        dimg0_row = subj_df.loc[subj_df['stimulus'] == img0_path]\n",
    "        \n",
    "        img1_path = 'depth_duration_stimuli/' + combo[1]\n",
    "        dimg1_row = subj_df.loc[subj_df['stimulus'] == img1_path]\n",
    "        \n",
    "        \n",
    "        if len(dimg0_row) == 1:\n",
    "             if len(dimg1_row) == 1:\n",
    "                if subj not in discrim_trial_subjects_1000[combo[0]]:\n",
    "                    discrim_trial_subjects_1000[combo[0]].append(subj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "17\n",
      "12\n",
      "11\n",
      "0\n",
      "10\n",
      "15\n",
      "12\n",
      "0\n",
      "13\n",
      "13\n",
      "14\n",
      "0\n",
      "11\n",
      "14\n",
      "8\n",
      "12\n",
      "5\n",
      "15\n",
      "0\n",
      "9\n",
      "12\n",
      "15\n",
      "12\n",
      "17\n",
      "0\n",
      "11\n",
      "14\n",
      "7\n",
      "0\n",
      "9\n",
      "16\n",
      "13\n",
      "8\n",
      "0\n",
      "11\n",
      "13\n",
      "0\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for key in discrim_trial_subjects_1000:\n",
    "    print(len(discrim_trial_subjects_1000[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because of outlier cleaning, the numbers are not even across all discrimination trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
