{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clutter x Discrimination Performance\n",
    "\n",
    "global clutter = # of labeled objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy \n",
    "import scipy.stats as stats\n",
    "from scipy.stats import sem \n",
    "from mpl_toolkits.mplot3d import Axes3D # <--- This is important for 3d plotting \n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load discrimination data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dir = '/Users/prachimahableshwarkar/Documents/GW/Depth_MTurk/depth_discrimination'\n",
    "# raw_dir = _dir + '/data/finalVEMatched/raw/'\n",
    "zs_dir = _dir + '/data/finalDiscrimMatched/z_scored_RT/'\n",
    "\n",
    "# final_data = pd.read_csv (raw_dir + '/raw_discrim.csv')\n",
    "zscored_data = pd.read_csv (zs_dir + 'final_discrim.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli_path = '/Users/prachimahableshwarkar/Documents/GW/Depth_MTurk/depth_duration_stimuli'\n",
    "kinect192_path = '/Users/prachimahableshwarkar/Documents/GW/SUNRGBD/updated/kinect2data_192'\n",
    "\n",
    "# stimuli_path = '/Users/pmahableshwarkar/Documents/Depth_Project/final_stimuli'\n",
    "# kinect192_path = '/Users/pmahableshwarkar/Documents/Depth_Project/SUNRGBD/kinect2data_192'\n",
    "\n",
    "objSA_data = {}\n",
    "\n",
    "for stim in os.listdir(stimuli_path):\n",
    "    if 'resize' in stim:\n",
    "        p = stimuli_path + '/' + stim + '/data.json'\n",
    "        data = json.load(open(p))\n",
    "        target_object = data['objects'][0]['name']\n",
    "        dbID = data['objects'][0]['dbID']\n",
    "        kp = kinect192_path + '/' + stim[:-2] + '/annotation2Dfinal'\n",
    "        for file in os.listdir(kp):\n",
    "            if 'objSA' in file:\n",
    "                objSA = json.load(open(kp + '/' + file))\n",
    "                objSA_data[stim[:-2]] = objSA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'floor_3': 3.689464597292053,\n",
       " 'bench_2': 1.6132601681688803,\n",
       " 'wall_4': 4.73195337315781,\n",
       " 'bench2_9': 5.5677571310778005,\n",
       " 'table_10': 5.180670126559448,\n",
       " 'wall2_11': 3.630879463416829}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objSA_data['000866_2014-06-09_20-45-42_260595134347_rgbf000139-resize']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Clutter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "p = '/Users/prachimahableshwarkar/Documents/GW/Depth_MTurk/verbal_judgement_analysis/cue_analyses/cleaned_globalClutter.json'\n",
    "f = open(p)\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "cleaned_globalClutter = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalClutter_dict = {}\n",
    "for stim in objSA_data:\n",
    "    count = 0\n",
    "    incl_obj = []\n",
    "    for key in objSA_data[stim]:\n",
    "#         sans_num_key = ''.join([i for i in key if not i.isdigit()])\n",
    "        if 'floor' in key: \n",
    "            count += 0\n",
    "#             print(key, 'floor')\n",
    "        elif 'wall' in key: count += 0\n",
    "        else: \n",
    "            count += 1\n",
    "            incl_obj.append(key)\n",
    "#             print(key, 'wall')\n",
    "            \n",
    "            \n",
    "        globalClutter_dict[stim] = [count, incl_obj]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, ['bench_2', 'bench2_9', 'table_10']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globalClutter_dict['000866_2014-06-09_20-45-42_260595134347_rgbf000139-resize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = '/Users/prachimahableshwarkar/Documents/GW/Depth_MTurk/depth_discrimination/data/finalDiscrimMatched/performance.pkl'\n",
    "unpickled_df = pd.read_pickle(p) \n",
    "len(unpickled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img = 'depth_discrimination_stimuli/000483_2014-06-09_20-41-45_260595134347_rgbf000116-resize_4/000483_2014-06-09_20-41-45_260595134347_rgbf000116-resize_4-target.png'\n",
    "\n",
    "# list_RTs, np.mean(list_RTs) ,np.std(list_RTs), stats.sem(list_RTs)\n",
    "# unpickled_df[sample_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrim_pc_125 = [unpickled_df[img]['accuracy_125'][0] for img in unpickled_df]\n",
    "discrim_pc_250 = [unpickled_df[img]['accuracy_250'][0] for img in unpickled_df]\n",
    "discrim_pc_1000 = [unpickled_df[img]['accuracy_1000'][0] for img in unpickled_df]\n",
    "\n",
    "\n",
    "discrim_zsRT_125 = [unpickled_df[img]['zsRT_125'][1] for img in unpickled_df]\n",
    "discrim_zsRT_250 = [unpickled_df[img]['zsRT_250'][1] for img in unpickled_df]\n",
    "discrim_zsRT_1000 = [unpickled_df[img]['zsRT_1000'][1] for img in unpickled_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 86)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# difference in clutter between the two images in a discrimination trial\n",
    "discrim_clutter_diff = []\n",
    "\n",
    "trunc_discrim_pc_125 = []\n",
    "trunc_discrim_pc_250 = []\n",
    "trunc_discrim_pc_1000 = []\n",
    "\n",
    "trunc_discrim_zsRT_125 = []\n",
    "trunc_discrim_zsRT_250 = []\n",
    "trunc_discrim_zsRT_1000 = []\n",
    "\n",
    "n = 0\n",
    "for i in range(len(unpickled_df)):\n",
    "    img = list(unpickled_df.keys())[i]\n",
    "    try:\n",
    "        scene0_clutter = globalClutter_dict[img.split('/')[1][:-2]][0]\n",
    "        scene1 = unpickled_df[img]['stimulus_1']\n",
    "        scene1_clutter = globalClutter_dict[scene1.split('/')[1][:-2]][0]\n",
    "        discrim_clutter_diff.append(abs(scene0_clutter - scene1_clutter))\n",
    "        \n",
    "        trunc_discrim_pc_125.append(discrim_pc_125[i])\n",
    "        trunc_discrim_pc_250.append(discrim_pc_250[i])\n",
    "        trunc_discrim_pc_1000.append(discrim_pc_1000[i])\n",
    "\n",
    "        trunc_discrim_zsRT_125.append(discrim_zsRT_125[i])\n",
    "        trunc_discrim_zsRT_250.append(discrim_zsRT_250[i])\n",
    "        trunc_discrim_zsRT_1000.append(discrim_zsRT_1000[i])\n",
    "\n",
    "        n += 1\n",
    "    except:\n",
    "        pass\n",
    "n, len(trunc_discrim_pc_125)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_avg_pc = np.mean([np.array(trunc_discrim_pc_125), np.array(trunc_discrim_pc_250), np.array(trunc_discrim_pc_1000)], axis =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between Discrimination PC and Global Clutter difference\n",
      "125 ms:  (0.02827389062742977, 0.7960857708840371)\n",
      "250 ms:  (-0.08968029767063544, 0.41156223364294137)\n",
      "1000 ms:  (0.05828728148278224, 0.5939796453248296)\n",
      "Avg:  (0.0008061571078380424, 0.9941223594627673)\n"
     ]
    }
   ],
   "source": [
    "print('Correlation between Discrimination PC and Global Clutter difference')\n",
    "print('125 ms: ',stats.pearsonr(trunc_discrim_pc_125, discrim_clutter_diff))\n",
    "print('250 ms: ',stats.pearsonr(trunc_discrim_pc_250, discrim_clutter_diff))\n",
    "print('1000 ms: ',stats.pearsonr(trunc_discrim_pc_1000, discrim_clutter_diff))\n",
    "\n",
    "print('Avg: ',stats.pearsonr(trunc_avg_pc, discrim_clutter_diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_avg_zsRT = np.mean([np.array(trunc_discrim_zsRT_125), np.array(trunc_discrim_zsRT_250), np.array(trunc_discrim_zsRT_1000)], axis =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between Discrimination z-scored RT and Global Clutter difference\n",
      "125 ms:  (0.19004138573881907, 0.07967205590607991)\n",
      "250 ms:  (-0.05163940417121923, 0.6367898540512763)\n",
      "1000 ms:  (0.045385288248122595, 0.6781851384741983)\n",
      "Avg:  (0.07066760960715109, 0.5179142669430751)\n"
     ]
    }
   ],
   "source": [
    "print('Correlation between Discrimination z-scored RT and Global Clutter difference')\n",
    "print('125 ms: ',stats.pearsonr(trunc_discrim_zsRT_125, discrim_clutter_diff))\n",
    "print('250 ms: ',stats.pearsonr(trunc_discrim_zsRT_250, discrim_clutter_diff))\n",
    "print('1000 ms: ',stats.pearsonr(trunc_discrim_zsRT_1000, discrim_clutter_diff))\n",
    "\n",
    "print('Avg: ',stats.pearsonr(trunc_avg_zsRT, discrim_clutter_diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
